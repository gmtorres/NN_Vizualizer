{"version":3,"sources":["components/DataGrid/DataGrid.module.css","components/Layout/Layout.module.css","components/Visual/VisualNN.module.css","components/Navbar/Navbar.jsx","NeuralNetwork/activation.js","NeuralNetwork/NeuralNetwork.js","NeuralNetwork/samplesNN.js","components/Visual/Node/Node.jsx","components/Visual/Edge/Edge.jsx","components/Visual/LayerDropDown.jsx","components/Visual/NN.jsx","components/Visual/VisualNN.jsx","components/Info/InfoBasic.jsx","components/Expression/Expression.jsx","components/Info/FeedForward.jsx","components/Info/Backpropagation.jsx","components/Layout/Topbar/TopbarData.jsx","components/Layout/Topbar/Topbar.jsx","components/Layout/InfoPanel.jsx","components/DataGrid/DataValue.jsx","components/DataGrid/DataAux.jsx","components/DataGrid/DataEntry.jsx","components/DataGrid/DataGrid.jsx","components/RangeBar/RangeBar.jsx","components/Layout/Layout.jsx","App.js","reportWebVitals.js","index.js","components/Layout/Topbar/Topbar.module.css","components/Visual/Node/Node.module.css","components/Navbar/Navbar.module.css","components/RangeBar/RangeBar.module.css"],"names":["module","exports","Navbar","className","styles","_navbar","_navbar_left","activation","linear","func","val","deriv","sigm","Math","exp","relu","relu2","NeuralNetwork","input_size","output_size","this","n_layers","bias","learning_rate","training_times","layers","layer_activation","max_height","createRandomNN","expression","action","t","lr","length","l","edges","i","getLayerSize","push","random","splice","value","NaN","edges_old","layer","setLayerActivation","addNode","index","name","hasOwnProperty","step_layer","step_node","resetVars","height","floor","undefined","n","round","randomize","size","n2","clearNodes","error","input_data","parseFloat","output_data","setInputLayer","layer_prev","sum","prev_n","last","in_expression","toFixed","String","raw","out_expression","backpropagation","feedforward","node","derivative","size_layer","d_sum","a","isFinite","console","log","prev_layer","node_expression","weight_expression","representation","Object","keys","layer_act","current_node","current_layer","obj","weights","forEach","samples","sample1","Node","props","x","y","r","value_text","isNaN","textAnchor","fontSize","error_text","isActiveClass","circle","active","isActive","cx","cy","stroke","strokeWidth","fill","React","Component","Edge","x1","y1","x2","y2","weight","b","r1","hypot","angle","atan2","n_r","PI","dest","total","middle","cos","sin","transform","LayerDropDown","useState","open","setOpen","options","opts","width","entries","map","opt","activation_opt","current","opt_active","style","onClick","display","NN","ref","createRef","buildModel","key","rep","neuralNetwork_rep","buttons","buttonsDivHeight","marginx","usable_height","min","dx","dy","max_h","addLayerButton","addLayer","changeActivation","bind","nn_rep","space","marginy","updateRepresentation","window","addEventListener","nn","node1","e","node2","toString","svgWrapper","VisualNN","state","divElement","clientHeight","setState","clientWidth","setHeight","setWidth","neuralNetwork","getRepresentation","num","InfoBasic","Expression","equations","Array","isArray","expressions","typesetEquations","tex","FeedForward","node_in_expression","node_out_expression","sigm_expression","tanh_expression","relu_expression","Backpropagation","example_expression","example_deriv_expression","basic_gradient_expression","gradient_expression","error_expression","error_weight_expression","error_node_expression_1","error_node_expression_2","error_node_expression_3","activation_deriv_expression_1","weight_in_expression_1","weight_in_expression_2","node_delta_expression_2","error_weight_expression_2","error_hidden_node_expression_1","weight_deriv","error_hidden_node_expression_2","final_expression_1","final_expression_2","final_expression_3","final_expression_4","src","process","alt","margin","TopbarData","title","component","Topbar","handleClick","item","TopbarItem","isNotActive","InfoPanel","tabName","InfoPanel_wrapper","InfoPanel_content","content_wrapper","DataValue","button","inputRef","input","type","onChange","callback","target","class_n","entry_value","label","entry_label","separator","entry_separator","remove","DataAux","entry_button","DataEntry","data","entry","label_in_key","label_out_key","input_labels","in","output_labels","out","removeEntry","in_size","classname","DataGrid","grid","changes","lables","changeLabels","out_size","changeData","removeDataEntry","currentValue","grid_wrapper","grid_container","overflowY","flex","overflowX","minHeight","grid_container_buttons","addInput","addEntry","addOutput","RangeBar","step","inverse","max","setValue","displayValue","setDisplayValue","handleChange","parseInt","slidecontainer","class","id","rs_label","info","Layout","setNNFromSample","temp_inp_labels","temp_out_labels","input_key","output_key","getInputLayerSize","getOutputLayerSize","resetDataIndex","current_index","input_index","import","setNN","slice","getDataEntry","incrementEntryIndex","feedforwardStepNode","feedforwardStepLayer","d","train","backpropagationLayer","backpropagationNode","temp","new_entry","labels_t","addInputNode","addOutputNode","deleteInputNode","deleteOutputNode","new_value","removeInput","removeOutput","changeInputLabels","changeOutputLabels","NNfunc","changeActivationLayer","splitScreen","leftPane","rightPane","flexDirection","buttons_container","div_buttons_container","feedForward","feedForwardStepLayer","feedForwardStepNode","backpropagate","backpropagateLayer","backpropagateNode","randomizeNN","generateNN","getTrainingTimes","setTrainingTimes","getLearningRate","setLearningRate","App","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"gGACAA,EAAOC,QAAU,CAAC,aAAe,+BAA+B,eAAiB,iCAAiC,MAAQ,wBAAwB,OAAS,yBAAyB,YAAc,8BAA8B,YAAc,8BAA8B,gBAAkB,kCAAkC,aAAe,+BAA+B,uBAAyB,2C,yCCAvYD,EAAOC,QAAU,CAAC,YAAc,4BAA4B,SAAW,yBAAyB,yBAA2B,yCAAyC,gBAAkB,gCAAgC,kBAAoB,kCAAkC,kBAAoB,kCAAkC,iBAAmB,iCAAiC,UAAY,0BAA0B,kBAAoB,kCAAkC,kBAAoB,kCAAkC,sBAAwB,sCAAsC,wBAA0B,0C,mBCAhmBD,EAAOC,QAAU,CAAC,SAAW,2BAA2B,WAAa,6BAA6B,eAAiB,iCAAiC,eAAiB,iCAAiC,WAAa,+B,0ICcpMC,EAXA,WAEb,OACE,qBAAKC,UAAWC,IAAOC,QAAvB,SACE,qBAAKF,UAAWC,IAAOE,aAAvB,0C,mDCWSC,EAnBE,CACbC,OAAS,CACLC,KAAO,SAACC,GAAD,OAASA,GAChBC,MAAQ,SAACD,GAAD,OAAS,IAErBE,KAAO,CACHH,KAAO,SAACC,GAAD,OAAS,GAAK,EAAIG,KAAKC,KAAKJ,KACnCC,MAAQ,SAACD,GAAD,OAASA,GAAO,EAAEA,KAE9BK,KAAO,CACHN,KAAO,SAACC,GAAD,OAASA,EAAM,EAAIA,EAAM,GAChCC,MAAQ,SAACD,GAAD,OAASA,EAAM,EAAI,EAAI,IAEnCM,MAAQ,CACJP,KAAO,SAACC,GAAD,OAASA,EAAM,EAAIA,EAAM,GAAIA,GACpCC,MAAQ,SAACD,GAAD,OAASA,EAAM,EAAI,EAAI,M,4OCblBO,E,WACjB,WAAYC,EAAWC,GAAa,oBAEhCC,KAAKC,SAAW,EAEhBD,KAAKE,MAAO,EAEZF,KAAKG,cAAgB,IACrBH,KAAKI,eAAiB,IAEtBJ,KAAKK,OAAS,GACdL,KAAKM,iBAAmB,GACxBN,KAAKO,WAAa,EAElBP,KAAKQ,eAAeV,EAAWC,GAE/BC,KAAKS,WAAa,GAElBT,KAAKU,OAAS,G,+DAId,OAAOV,KAAKI,iB,uCAECO,GACbX,KAAKI,eAAiBO,I,wCAGtB,OAAOX,KAAKG,gB,sCAEAS,GACZZ,KAAKG,cAAgBS,I,0CAIrB,OAAGZ,KAAKE,KACGF,KAAKK,OAAO,GAAGQ,OAAS,EAC5Bb,KAAKK,OAAO,GAAGQ,S,2CAItB,OAAOb,KAAKK,OAAOL,KAAKK,OAAOQ,OAAO,GAAGA,S,mCAGhCC,GACT,OAAGA,IAAMd,KAAKK,OAAOQ,OAAO,EACjBb,KAAKK,OAAOS,GAAGD,OACvBb,KAAKE,KACGF,KAAKK,OAAOS,GAAGD,OAAS,EAC5Bb,KAAKK,OAAOS,GAAGD,S,qCAKtB,IADA,IAAIE,EAAQ,GACJC,EAAI,EAAGA,EAAIhB,KAAKiB,aAAa,GAAGD,IACpCD,EAAMG,KAAKzB,KAAK0B,UAEpBnB,KAAKK,OAAO,GAAGe,OAAOpB,KAAKiB,aAAa,GAAG,EAAE,CAACI,MAAQC,IAAKP,MAAQA,EAAOQ,UAAS,UAAOR,KACvFf,KAAKK,OAAO,GAAGQ,OAASb,KAAKO,aAC5BP,KAAKO,WAAaP,KAAKK,OAAO,GAAGQ,U,sCAIrC,IAAI,IAAKG,EAAI,EAAGA,EAAIhB,KAAKK,OAAOL,KAAKK,OAAOQ,OAAO,GAAGA,OAAOG,IACzDhB,KAAKK,OAAOL,KAAKK,OAAOQ,OAAO,GAAGG,GAAGD,MAAMG,KAAKzB,KAAK0B,UAEzDnB,KAAKK,OAAOL,KAAKK,OAAOQ,OAAO,GAAGK,KAAK,CAACG,MAAQC,IAAKP,MAAQ,CAAC,KAC3Df,KAAKK,OAAOL,KAAKK,OAAOQ,OAAO,GAAGA,OAASb,KAAKO,aAC/CP,KAAKO,WAAaP,KAAKK,OAAOL,KAAKK,OAAOQ,OAAO,GAAGA,U,8BAEpDW,GACJ,IAAI,IAAKR,EAAI,EAAGA,EAAIhB,KAAKK,OAAOmB,EAAM,GAAGX,OAAOG,IAC5ChB,KAAKK,OAAOmB,EAAM,GAAGR,GAAGD,MAAMG,KAAKzB,KAAK0B,UAG5C,IADA,IAAIJ,EAAQ,GACJC,EAAI,EAAGA,EAAIhB,KAAKiB,aAAaO,EAAM,GAAIR,IAC3CD,EAAMG,KAAKzB,KAAK0B,UAEpBnB,KAAKK,OAAOmB,GAAOJ,OAAOpB,KAAKiB,aAAaO,GAAO,EAAE,CAACH,MAAQC,IAAKP,MAAQA,EAAOQ,UAAS,UAAOR,KAC/Ff,KAAKK,OAAOmB,GAAOX,OAASb,KAAKO,aAChCP,KAAKO,WAAaP,KAAKK,OAAOmB,GAAOX,U,+BAGpCW,GACL,IAAI,IAAIR,EAAI,EAAGA,EAAIhB,KAAKK,OAAOmB,GAAOX,OAAOG,IACzChB,KAAKK,OAAOmB,GAAOR,GAAGD,MAAQ,GAGlC,GADAf,KAAKK,OAAOe,OAAOI,EAAM,EAAE,EAAE,IAC1BxB,KAAKE,KAAK,CAET,IADA,IAAIa,EAAQ,GACJC,EAAI,EAAGA,EAAIhB,KAAKiB,aAAaO,EAAM,GAAIR,IAC3CD,EAAMG,KAAKzB,KAAK0B,UAEpBnB,KAAKK,OAAOmB,EAAM,GAAGN,KAAK,CAACG,MAAQ,EAAGN,MAAQA,EAAQQ,UAAS,UAAOR,KAG1Ef,KAAKM,iBAAiBc,OAAOI,EAAM,EAAE,EAAE,MACvCxB,KAAKyB,mBAAmBD,EAAM,EAAE,QAChCxB,KAAK0B,QAAQF,EAAM,K,sCAGPG,GACZ3B,KAAKK,OAAO,GAAGe,OAAOO,EAAM,GAC5B3B,KAAKO,WAAa,EAClB,IAAI,IAAIS,EAAI,EAAGA,EAAIhB,KAAKK,OAAOQ,OAAOG,IAC/BhB,KAAKK,OAAOW,GAAGH,OAASb,KAAKO,aAC5BP,KAAKO,WAAaP,KAAKK,OAAOW,GAAGH,U,uCAE5Bc,GACb,IAAI,IAAKX,EAAI,EAAGA,EAAIhB,KAAKK,OAAOL,KAAKK,OAAOQ,OAAO,GAAGA,OAAOG,IACzDhB,KAAKK,OAAOL,KAAKK,OAAOQ,OAAO,GAAGG,GAAGD,MAAMK,OAAOO,EAAM,GAE5D3B,KAAKK,OAAOL,KAAKK,OAAOQ,OAAO,GAAGO,OAAOO,EAAM,GAC/C3B,KAAKO,WAAa,EAClB,IAAI,IAAIS,EAAI,EAAGA,EAAIhB,KAAKK,OAAOQ,OAAOG,IAC/BhB,KAAKK,OAAOW,GAAGH,OAASb,KAAKO,aAC5BP,KAAKO,WAAaP,KAAKK,OAAOW,GAAGH,U,yCAG1BW,EAAMI,GACjBzC,EAAW0C,eAAeD,KAC9B5B,KAAKM,iBAAiBkB,GAAS,CAACI,KAAOA,EAAMzC,WAAaA,EAAWyC,O,kCAKrE5B,KAAK8B,WAAa,KAClB9B,KAAK+B,UAAY,O,qCAGNjC,EAAWC,GACtBC,KAAKgC,YACLhC,KAAKK,OAAS,GACdL,KAAKO,WAAa,EAClB,IAAI,IAAIO,EAAI,EAAGA,EAAId,KAAKC,SAAUa,IAAI,CAClC,IAAIU,EAAQ,GACRS,EAASxC,KAAKyC,MAAsB,EAAhBzC,KAAK0B,UAAgB,EAEpC,IAANL,GAA0B,OAAfhB,QAAsCqC,IAAfrC,IACjCmC,EAASnC,GACVgB,IAAMd,KAAKC,SAAS,GAAqB,OAAhBF,QAAwCoC,IAAhBpC,IAChDkC,EAASlC,GACb,IAAI,IAAIqC,EAAI,EAAGA,EAAIH,EAAQG,IACvBZ,EAAMN,KAAK,CAACG,MAAQ5B,KAAK4C,MAAoB,IAAd5C,KAAK0B,UAAe,IAAMJ,MAAQ,KAElEf,KAAKE,MAAQY,IAAMd,KAAKC,SAAS,GAChCuB,EAAMN,KAAK,CAACG,MAAQ,EAAGN,MAAQ,KAChCS,EAAMX,OAASb,KAAKO,aAAYP,KAAKO,WAAaiB,EAAMX,QAC3Db,KAAKK,OAAOa,KAAKM,GACjBxB,KAAKyB,mBAAmBX,EAAE,QAE9Bd,KAAKsC,c,kCAILtC,KAAKgC,YACL,IAAI,IAAIlB,EAAI,EAAGA,EAAId,KAAKK,OAAOQ,OAAQC,IACnC,IAAI,IAAIsB,EAAI,EAAGA,EAAIpC,KAAKK,OAAOS,GAAGD,OAAQuB,IAEtC,GADApC,KAAKK,OAAOS,GAAGsB,GAAGrB,MAAQ,GACvBD,IAAMd,KAAKK,OAAOQ,OAAO,EACxBb,KAAKK,OAAOS,GAAGsB,GAAGrB,MAAMG,KAAK,OAC7B,CACA,IAAIqB,EAAOvC,KAAKK,OAAOS,EAAE,GAAGD,OACzBC,EAAE,EAAId,KAAKK,OAAOQ,OAAS,GAAKb,KAAKE,OAAMqC,GAAQ,GACtD,IAAI,IAAIC,EAAK,EAAGA,EAAKD,EAAMC,IACvBxC,KAAKK,OAAOS,GAAGsB,GAAGrB,MAAMG,KAAKzB,KAAK0B,UACtCnB,KAAKK,OAAOS,GAAGsB,GAAGb,UAAYvB,KAAKK,OAAOS,GAAGsB,GAAGrB,MAI5Df,KAAKyC,e,mCAIL,IAAI,IAAI3B,EAAI,EAAGA,EAAId,KAAKK,OAAOQ,OAAQC,IAAI,CACvC,IAAIyB,EAAOvC,KAAKK,OAAOS,GAAGD,OACvBC,EAAId,KAAKK,OAAOQ,OAAO,GAAKb,KAAKE,OAAMqC,GAAQ,GAClD,IAAI,IAAIH,EAAI,EAAGA,EAAIG,EAAMH,IACrBpC,KAAKK,OAAOS,GAAGsB,GAAGf,MAAQC,IAC1BtB,KAAKK,OAAOS,GAAGsB,GAAGM,MAAQpB,O,oCAIxBqB,GACV,GAAiB,MAAdA,EACC,IAAI,IAAI3B,EAAI,EAAGA,EAAI2B,EAAW9B,OAAOG,IACjChB,KAAKK,OAAO,GAAGW,GAAGK,MAAQuB,WAAWD,EAAW3B,M,kCAKhD2B,EAAYE,GACpB7C,KAAK8C,cAAcH,GACnB,IAAI,IAAI7B,EAAI,EAAGA,EAAId,KAAKK,OAAOQ,OAAQC,IAInC,IAFA,IAAIiC,EAAa/C,KAAKK,OAAOS,EAAE,GAC3B3B,EAAaa,KAAKM,iBAAiBQ,GAAG3B,WAAWE,KAC7C+C,EAAI,EAAGA,EAAIpC,KAAKiB,aAAaH,GAAIsB,IAAI,CAEzC,IADA,IAAIY,EAAM,EACFC,EAAS,EAAGA,EAASF,EAAWlC,OAAOoC,IAC3CD,GAAMD,EAAWE,GAAQ5B,MAAQ0B,EAAWE,GAAQlC,MAAMqB,GAE9DpC,KAAKK,OAAOS,GAAGsB,GAAGf,MAAQlC,EAAW6D,GAI7C,GAAkB,MAAfH,EAEC,IADA,IAAIK,EAAOlD,KAAKK,OAAOQ,OAAO,EACtBG,EAAI,EAAGA,EAAIhB,KAAKK,OAAO6C,GAAMrC,OAAQG,IACzChB,KAAKK,OAAO6C,GAAMlC,GAAG0B,MAAQ1C,KAAKK,OAAO6C,GAAMlC,GAAGK,MAAQwB,EAAY7B,K,0CAO9D2B,EAAYE,GAG5B,GADA7C,KAAKS,WAAa,GACG,MAAlBT,KAAK+B,WAAqC,gBAAhB/B,KAAKU,OAO9B,OANAV,KAAKU,OAAS,cACdV,KAAK+B,UAAY,EACjB/B,KAAKyC,aACLzC,KAAK8C,cAAcH,GACG,MAAnB3C,KAAK8B,aACJ9B,KAAK8B,WAAa,IACf,EAEX,IAAIiB,EAAa/C,KAAKK,OAAOL,KAAK8B,WAAW,GACzCkB,EAAM,EAENG,EAAgB,GACpBA,GAAa,aAAUnD,KAAK+B,UAAf,YAA4B/B,KAAK8B,WAAjC,KAEb,IAAI,IAAImB,EAAS,EAAGA,EAASF,EAAWlC,OAAOoC,IAC3CE,GAAiBJ,EAAWE,GAAQ5B,MAAM+B,QAAQ,GAAK,IAAML,EAAWE,GAAQlC,MAAMf,KAAK+B,WAAWqB,QAAQ,GAC3GH,IAAWF,EAAWlC,OAAS,IAC9BsC,GAAgB,KACpBH,GAAMD,EAAWE,GAAQ5B,MAAQ0B,EAAWE,GAAQlC,MAAMf,KAAK+B,WAEnEoB,GAAiB,MAAQH,EAAII,QAAQ,GACrCpD,KAAKS,WAAWS,KAAKmC,OAAOC,IAA5B,IAAkCH,IAElC,IAAII,EAAiB,GAWrB,OAVAvD,KAAKK,OAAOL,KAAK8B,YAAY9B,KAAK+B,WAAWV,MAAQrB,KAAKM,iBAAiBN,KAAK8B,YAAY3C,WAAWE,KAAK2D,GAC5GO,GAAkB,cAAOvD,KAAK+B,UAAZ,YAAyB/B,KAAK8B,WAA9B,0BAA0D9B,KAAK+B,UAA/D,YAA4E/B,KAAK8B,WAAjF,MAAiG9B,KAAKM,iBAAiBN,KAAK8B,YAAYF,KAAM,IAAMoB,EAAII,QAAQ,GAAK,KAAOpD,KAAKK,OAAOL,KAAK8B,YAAY9B,KAAK+B,WAAWV,MAAM+B,QAAQ,GAEzPpD,KAAKS,WAAWS,KAAKmC,OAAOC,IAA5B,IAAkCC,IAElCvD,KAAK+B,YACF/B,KAAK+B,WAAa/B,KAAKiB,aAAajB,KAAK8B,cACxC9B,KAAK+B,UAAY,EACjB/B,KAAK8B,cAEN9B,KAAK8B,YAAc9B,KAAKK,OAAOQ,SAC9Bb,KAAK8B,WAAa,KAClB9B,KAAK+B,UAAY,KACjB/B,KAAKU,OAAS,IACP,K,2CAKMiC,EAAYE,GAE7B,GADA7C,KAAKS,WAAa,GACI,MAAnBT,KAAK8B,YAAsC,gBAAhB9B,KAAKU,OAK/B,OAJAV,KAAKU,OAAS,cACdV,KAAK8B,WAAa,EAClB9B,KAAKyC,aACLzC,KAAK8C,cAAcH,IACZ,EAOX,IAHA,IAAII,EAAa/C,KAAKK,OAAOL,KAAK8B,WAAW,GACzCM,EAAuB,MAAlBpC,KAAK+B,UAAqB,EAAI/B,KAAK+B,UACxC5C,EAAaa,KAAKM,iBAAiBN,KAAK8B,YAAY3C,WAAWE,KAC7D+C,EAAIpC,KAAKiB,aAAajB,KAAK8B,YAAaM,IAAI,CAE9C,IADA,IAAIY,EAAM,EACFC,EAAS,EAAGA,EAASF,EAAWlC,OAAOoC,IAC3CD,GAAMD,EAAWE,GAAQ5B,MAAQ0B,EAAWE,GAAQlC,MAAMqB,GAE9DpC,KAAKK,OAAOL,KAAK8B,YAAYM,GAAGf,MAAQlC,EAAW6D,GAIvD,OAFAhD,KAAK8B,aAEF9B,KAAK8B,YAAc9B,KAAKK,OAAOQ,SAC9Bb,KAAK8B,WAAa,KAClB9B,KAAK+B,UAAY,KACjB/B,KAAKU,OAAS,IACP,K,4BAKTiC,EAAYE,GACd7C,KAAKS,WAAa,GAClB,IAAI,IAAIE,EAAI,EAAGA,EAAIX,KAAKI,eAAgBO,IACpC,IAAI,IAAIK,EAAI,EAAGA,EAAI2B,EAAW9B,OAAQG,IAClChB,KAAKwD,gBAAgBb,EAAW3B,GAAG6B,EAAY7B,M,sCAG3C2B,EAAYE,GACxB7C,KAAKyD,YAAYd,EAAWE,GAE5B,IADA,IAAIK,EAAOlD,KAAKK,OAAOQ,OAAO,EACtBG,EAAI,EAAGA,EAAIhB,KAAKK,OAAO6C,GAAMrC,OAAOG,IAAI,CAC5C,IAAI0C,EAAO1D,KAAKK,OAAO6C,GAAMlC,GAC7B0C,EAAKC,WAAa3D,KAAKM,iBAAiB,GAAGnB,WAAWI,MAAMmE,EAAKrC,OAASqC,EAAKhB,MAEnF,IAAI,IAAI5B,EAAIoC,EAAK,EAAGpC,GAAK,EAAGA,IAGxB,IAFA,IAAI8C,EAAa5D,KAAKK,OAAOS,GAAGD,OAC5B8C,EAAa3D,KAAKM,iBAAiBQ,GAAG3B,WAAWI,MAC7CyB,EAAI,EAAGA,EAAI4C,EAAY5C,IAAI,CAG/B,IAFA,IAAI0C,EAAO1D,KAAKK,OAAOS,GAAGE,GACtB6C,EAAQ,EACJC,EAAI,EAAGA,EAAIJ,EAAK3C,MAAMF,OAAOiD,IACjCD,GAAS7D,KAAKK,OAAOS,GAAGE,GAAGD,MAAM+C,GAAK9D,KAAKK,OAAOS,EAAE,GAAGgD,GAAGH,WAE9DD,EAAKC,WAAaE,EAAQF,EAAWD,EAAKrC,OAGlD,IAAI,IAAIP,EAAIoC,EAAK,EAAGpC,GAAK,EAAGA,IAExB,IADA,IAAI8C,EAAa5D,KAAKK,OAAOS,GAAGD,OACxBG,EAAI,EAAGA,EAAI4C,EAAY5C,IAE3B,IADA,IAAI0C,EAAO1D,KAAKK,OAAOS,GAAGE,GAClB8C,EAAI,EAAGA,EAAIJ,EAAK3C,MAAMF,OAAOiD,IAC7BC,SAASL,EAAK3C,MAAM+C,MACxBJ,EAAK3C,MAAM+C,IAAMJ,EAAKrC,MAAQrB,KAAKK,OAAOS,EAAE,GAAGgD,GAAGH,WAAa3D,KAAKG,cACpE6D,QAAQC,IAAIP,EAAK3C,MAAM+C,O,2CAMlBnB,EAAYE,GAE7B,GADA7C,KAAKS,WAAa,GACI,MAAnBT,KAAK8B,YAAsC,oBAAhB9B,KAAKU,OAI/B,OAHAV,KAAKU,OAAS,kBACdV,KAAKyD,YAAYd,EAAWE,GAC5B7C,KAAK8B,WAAa9B,KAAKK,OAAOQ,OAAO,GAC9B,EAEX,IAAIqD,EAAalE,KAAK8B,WAAa,EAEnC,GAAG9B,KAAK8B,aAAe9B,KAAKK,OAAOQ,OAAO,EACtC,IAAI,IAAIG,EAAI,EAAGA,EAAIhB,KAAKK,OAAOL,KAAK8B,YAAYjB,OAAOG,IAAI,CACvD,IAAI0C,EAAO1D,KAAKK,OAAOL,KAAK8B,YAAYd,GACxC0C,EAAKC,WAAa3D,KAAKM,iBAAiB,GAAGnB,WAAWI,MAAMmE,EAAKrC,OAASqC,EAAKhB,WAKnF,IAFA,IAAIkB,EAAa5D,KAAKK,OAAOL,KAAK8B,YAAYjB,OAC1C8C,EAAa3D,KAAKM,iBAAiBN,KAAK8B,YAAY3C,WAAWI,MAC3DyB,EAAI,EAAGA,EAAI4C,EAAY5C,IAAI,CAG/B,IAFA,IAAI0C,EAAO1D,KAAKK,OAAOL,KAAK8B,YAAYd,GACpC6C,EAAQ,EACJC,EAAI,EAAGA,EAAIJ,EAAK3C,MAAMF,OAAOiD,IACjCD,GAAS7D,KAAKK,OAAOL,KAAK8B,YAAYd,GAAGO,UAAUuC,GAAK9D,KAAKK,OAAOL,KAAK8B,WAAW,GAAGgC,GAAGH,WAE9FD,EAAKC,WAAaE,EAAQF,EAAWD,EAAKrC,OAKlD,IADA,IAAIuC,EAAa5D,KAAKK,OAAO6D,GAAYrD,OACjCG,EAAI,EAAGA,EAAI4C,EAAY5C,IAE3B,IADA,IAAI0C,EAAO1D,KAAKK,OAAO6D,GAAYlD,GAC3B8C,EAAI,EAAGA,EAAIJ,EAAK3C,MAAMF,OAAOiD,IAC7BC,SAASL,EAAK3C,MAAM+C,MACxBJ,EAAKnC,UAAUuC,GAAKJ,EAAK3C,MAAM+C,GAC/BJ,EAAK3C,MAAM+C,IAAMJ,EAAKrC,MAAQrB,KAAKK,OAAOL,KAAK8B,YAAYgC,GAAGH,WAAa3D,KAAKG,cAChF6D,QAAQC,IAAIP,EAAK3C,MAAM+C,KAK/B,OADA9D,KAAK8B,aACF9B,KAAK8B,YAAc,IAClB9B,KAAK8B,WAAa,KAClB9B,KAAK+B,UAAY,KACjB/B,KAAKU,OAAS,IACP,K,0CAKKiC,EAAYE,GAE5B,GADA7C,KAAKS,WAAa,GACG,MAAlBT,KAAK+B,WAAqC,oBAAhB/B,KAAKU,OAM9B,OALAV,KAAKU,OAAS,kBACdV,KAAKyD,YAAYd,EAAWE,GAC5B7C,KAAK+B,UAAY,EACK,MAAnB/B,KAAK8B,aACJ9B,KAAK8B,WAAa9B,KAAKK,OAAOQ,OAAO,IAClC,EAGX,IAAIsD,EAAkBd,OAAOC,IAAV,KACnBa,GAAe,eAAYnE,KAAK8B,WAAjB,YAA+B9B,KAAK+B,UAApC,OAEf,IAAImC,EAAalE,KAAK8B,WAAa,EAEnC,GAAG9B,KAAK8B,aAAe9B,KAAKK,OAAOQ,OAAO,EAAE,CAExC,IAAI6C,EAAO1D,KAAKK,OAAOL,KAAK8B,YAAY9B,KAAK+B,WAC7C2B,EAAKC,WAAa3D,KAAKM,iBAAiB,GAAGnB,WAAWI,MAAMmE,EAAKrC,OAASqC,EAAKhB,MAC/EyB,GAAmBnE,KAAKM,iBAAiB,GAAGnB,WAAWI,MAAMmE,EAAKrC,OAAO+B,QAAQ,GAAK,IAAMM,EAAKhB,MAAMU,QAAQ,GAC/Ge,GAAmB,IAAMT,EAAKC,WAAWP,QAAQ,OAChD,CACD,IAAIO,EAAa3D,KAAKM,iBAAiBN,KAAK8B,YAAY3C,WAAWI,MAE/DmE,EAAO1D,KAAKK,OAAOL,KAAK8B,YAAY9B,KAAK+B,WACzC8B,EAAQ,EACZM,GAAmB,IACnB,IAAI,IAAIL,EAAI,EAAGA,EAAIJ,EAAK3C,MAAMF,OAAOiD,IACjCD,GAAS7D,KAAKK,OAAOL,KAAK8B,YAAY9B,KAAK+B,WAAWR,UAAUuC,GAAK9D,KAAKK,OAAOL,KAAK8B,WAAW,GAAGgC,GAAGH,WACvGQ,GAAmBnE,KAAKK,OAAOL,KAAK8B,WAAW,GAAGgC,GAAGH,WAAWP,QAAQ,GAAK,IAAMpD,KAAKK,OAAOL,KAAK8B,YAAY9B,KAAK+B,WAAWR,UAAUuC,GAAGV,QAAQ,GAClJU,IAAMJ,EAAK3C,MAAMF,OAAS,IAAGsD,GAAmB,KAEvDA,GAAmB,IACnBT,EAAKC,WAAaE,EAAQF,EAAWD,EAAKrC,OAC1C8C,GAAmB,IAAMR,EAAWD,EAAKrC,OAAO+B,QAAQ,GACxDe,GAAmB,IAAMT,EAAKC,WAAWP,QAAQ,GAErDpD,KAAKS,WAAWS,KAAKiD,GAGrB,IADA,IAAIP,EAAa5D,KAAKK,OAAO6D,GAAYrD,OACjCG,EAAI,EAAGA,EAAI4C,EAAY5C,IAAI,CAC/B,IAAIoD,EAAoB,GACpBV,EAAO1D,KAAKK,OAAO6D,GAAYlD,GAE/B+C,SAASL,EAAK3C,MAAMf,KAAK+B,cAC7B2B,EAAKnC,UAAUvB,KAAK+B,WAAa2B,EAAK3C,MAAMf,KAAK+B,WACjD2B,EAAK3C,MAAMf,KAAK+B,YAAc2B,EAAKrC,MAAQrB,KAAKK,OAAOL,KAAK8B,YAAY9B,KAAK+B,WAAW4B,WAAa3D,KAAKG,cAC1G6D,QAAQC,IAAIP,EAAK3C,MAAMf,KAAK+B,YAC5BqC,GAAqB,kBAAWpD,EAAX,YAAgBhB,KAAK+B,UAArB,aAAmCmC,EAAnC,KAAmDR,EAAKnC,UAAUvB,KAAK+B,WAAWqB,QAAQ,GAAK,IAAMpD,KAAKG,cAAciD,QAAQ,GAAK,IAAMpD,KAAKK,OAAOL,KAAK8B,YAAY9B,KAAK+B,WAAW4B,WAAWP,QAAQ,GAAK,IAAMM,EAAKrC,MAAM+B,QAAQ,GAC9PgB,GAAqB,IAAMV,EAAK3C,MAAMf,KAAK+B,WAAWqB,QAAQ,GAC9DpD,KAAKS,WAAWS,KAAKkD,IASzB,OALApE,KAAK+B,YACF/B,KAAK+B,WAAa/B,KAAKiB,aAAajB,KAAK8B,cACxC9B,KAAK+B,UAAY,EACjB/B,KAAK8B,cAEN9B,KAAK8B,YAAc,IAClB9B,KAAK8B,WAAa,KAClB9B,KAAK+B,UAAY,KACjB/B,KAAKU,OAAS,IACP,K,0CAQX,MAAO,CACH2D,eAAiBrE,KAAKK,OACtB4B,OAASjC,KAAKO,WACdpB,WAAamF,OAAOC,KAAKpF,GACzBqF,UAAYxE,KAAKM,iBACjBmE,aAAezE,KAAK+B,UACpB2C,cAAgB1E,KAAK8B,c,+BAKzB,IAAI6C,EAAM,CACNxE,cAAgBH,KAAKG,cACrBD,KAAOF,KAAKE,MAEZ0E,EAAU,GAOd,OANA5E,KAAKK,OAAOwE,SAAQ,SAAArD,GAChB,IAAIV,EAAI,GACRU,EAAMqD,SAAQ,SAAAnB,GAAI,OAAI5C,EAAEI,KAAKwC,EAAK3C,UAClC6D,EAAQ1D,KAAKJ,MAEjB6D,EAAIC,QAAUA,EACPD,I,6BAGJA,GAAK,IAAD,OACP3E,KAAKK,OAAS,GACdL,KAAKO,WAAa,EAClBP,KAAKE,KAAOyE,EAAIzE,KAChBF,KAAKG,cAAgBwE,EAAIxE,cACzBwE,EAAIC,QAAQC,SAAQ,SAAArD,GAChB,IAAIV,EAAI,GACRU,EAAMqD,SAAQ,SAAA9D,GACV,IAAI2C,EAAO,CAAC3C,MAAMA,EAAMQ,UAAU,YAAIR,IACnC,EAAKb,MAAQY,EAAED,SAAWW,EAAMX,OAAO,GAAK,EAAKR,OAAOQ,SAAW8D,EAAIC,QAAQ/D,OAAO,IACrF6C,EAAKrC,MAAQ,GACjBP,EAAEI,KAAKwC,MAEX,EAAKrD,OAAOa,KAAKJ,GACdU,EAAMX,OAAS,EAAKN,aAAY,EAAKA,WAAaiB,EAAMX,WAE/Db,KAAKC,SAAWD,KAAKK,OAAOQ,W,KCjcrBiE,EAjDD,CAEVC,QAAU,CACN,cAAiB,GACjB,MAAQ,EACR,QAAW,CACT,CACE,CACE,IACA,KAEF,CACE,GACA,IAEF,CACE,IACA,MAGJ,CACE,CACE,GACA,IAEF,CACE,IACA,KAEF,CACE,GACA,KAGJ,CACE,CACE,GAEF,CACE,O,iBCLCC,E,kDA5BX,WAAYC,GAAO,IAAD,8BACd,cAAMA,IACDC,EAAID,EAAMC,EAAID,EAAMC,EAAI,GAC7B,EAAKC,EAAIF,EAAME,EAAIF,EAAME,EAAI,GAC7B,EAAKC,EAAIH,EAAMG,EAAIH,EAAMG,EAAI,GAJf,E,qDASd,IAAIC,EAAa,IACbrF,KAAKiF,MAAM5D,QAAUiE,MAAMtF,KAAKiF,MAAM5D,QAAgC,IAArBrB,KAAKiF,MAAM5D,SAC5DgE,EAAa,uBAAuCH,EAAGlF,KAAKkF,EAAGC,EAAGnF,KAAKmF,EACvDI,WAAW,SAASC,SAAS,UADhC,eAC6CxF,KAAKiF,MAAM5D,UACzE,IAAIoE,EAAa,GACdzF,KAAKiF,MAAMvC,QAAU4C,MAAMtF,KAAKiF,MAAMvC,SACrC+C,EAAa,uBAAuCP,EAAGlF,KAAKkF,EAAGC,EAAGnF,KAAKmF,EAAEnF,KAAKoF,EAAE,EAChEG,WAAW,SAASC,SAAS,UADhC,eAC6CxF,KAAKiF,MAAMvC,UACzE,IAAIgD,EAAgB1G,IAAO2G,OAAS,KAAO3F,KAAKiF,MAAMW,OAAS5G,IAAO6G,SAAW,IACjF,OACI,oBAAG9G,UAAWC,IAAO0E,KAArB,UACI,wBAAQ3E,UAAW2G,EAAeI,GAAI9F,KAAKkF,EAAGa,GAAI/F,KAAKmF,EAAGC,EAAGpF,KAAKoF,EAAGY,OAAO,QAAQC,YAAY,IAAIC,KAAK,UACxGb,EACAI,S,GAxBEU,IAAMC,WCkCVC,E,kDAlCX,WAAYpB,GAAO,IAAD,8BACd,gBACKqB,GAAKrB,EAAMqB,GAAKrB,EAAMqB,GAAK,GAChC,EAAKC,GAAKtB,EAAMsB,GAAKtB,EAAMsB,GAAK,GAChC,EAAKC,GAAKvB,EAAMuB,GAAKvB,EAAMuB,GAAK,IAChC,EAAKC,GAAKxB,EAAMwB,GAAKxB,EAAMwB,GAAK,IAChC,EAAKC,OAASzB,EAAMyB,OAASzB,EAAMyB,YAASvE,EAN9B,E,qDAUd,IAEqB2B,EAAE6C,EAAEC,EAFrBxB,EAAI3F,KAAKoH,MAAM7G,KAAKuG,GAAGvG,KAAKyG,GAAGzG,KAAKsG,GAAGtG,KAAKwG,IAC5CM,EAAQrH,KAAKsH,MAAM/G,KAAKyG,GAAGzG,KAAKuG,GAAGvG,KAAKwG,GAAGxG,KAAKsG,IAIhDU,GAHiBlD,GAGJrE,KAAKwH,GAAG,EAHFN,EAGKlH,KAAKwH,GAAG,EAHXL,EAGa,GACtCI,GAAOhH,KAAKiF,MAAMiC,KAAK,IAAIlH,KAAKiF,MAAMkC,MAAM,GAAG/B,EAAE,IACjD,IAAIgC,EAAS,CAAClC,EAAIlF,KAAKsG,GAAKU,EAAIvH,KAAK4H,IAAIP,GAAQ3B,EAAInF,KAAKuG,GAAKS,EAAIvH,KAAK6H,IAAIR,IAC5EA,EAAgB,IAARA,EAAcrH,KAAKwH,GAE3B,IAAIM,EAAS,iBAAaT,EAAb,aAAuBM,EAAOlC,EAA9B,aAAoCkC,EAAOjC,EAA3C,KACb,OACI,8BACI,sBAAMmB,GAAItG,KAAKsG,GAAIC,GAAIvG,KAAKuG,GAAIC,GAAIxG,KAAKwG,GAAIC,GAAIzG,KAAKyG,GAAIT,OAAO,UACjE,sBAAMd,EAAGkC,EAAOlC,EAAGC,EAAGiC,EAAOjC,EAAI,GAAII,WAAW,SAASC,SAAS,UAAU+B,UAAWA,EAAvF,SAAoGvH,KAAK0G,gB,GA1BtGP,IAAMC,W,iBC4CVoB,EA1CQ,SAACvC,GAAW,IAAD,EAENwC,oBAAS,GAFH,mBAEvBC,EAFuB,KAEjBC,EAFiB,KAIxBC,EAAU3C,EAAM4C,KAEhBC,EAAQ,GAEVC,EAAUH,EAAQI,KAAI,SAACC,EAAIjH,GAE3B,IAAIjC,EAAYC,IAAOkJ,eAAiB,IAExC,OADAnJ,GAAakJ,IAAQhD,EAAMkD,QAAQvG,KAAO5C,IAAOoJ,WAAa,GAE1D,8BACI,sBAAMrJ,UAAWA,EAAWmG,EAAGD,EAAMC,EAAI4C,GAAS3C,EAAGF,EAAME,EAAEF,EAAMG,EAAE,EAAI,GAAKpE,EAAG8G,MAAOA,EAAO7F,OAAO,KAClGoG,MAAO,CAACrC,OAAO,kBACnB,sBAAMd,EAAGD,EAAMC,EAAI,EAAI4C,GAAS3C,EAAGF,EAAME,EAAEF,EAAMG,EAAE,EAAI,IAAMpE,EAAE,GAAK,EAAGwE,SAAS,UAAhF,SAA2FyC,IAC3F,sBAAO/C,EAAGD,EAAMC,EAAI4C,GAAS3C,EAAGF,EAAME,EAAEF,EAAMG,EAAE,EAAI,GAAKpE,EAAG8G,MAAOA,EAAO7F,OAAO,KAC7EoG,MAAO,CAACnC,KAAK,eACboC,QAAS,WAAOrD,EAAM5F,KAAK4I,GAAKN,GAAQ,QANxC,YAAY3G,MAWxBuH,EAAUb,EAAO,QAAU,OAE/B,OACI,8BACI,sBAAOxC,EAAGD,EAAMC,EAAI4C,GAAS3C,EAAGF,EAAME,EAAEF,EAAMG,EAAE,EAAI,GAAI0C,MAAOA,EAAO7F,OAAO,KAAKoG,MAAO,CAACnC,KAAK,mBAAmBF,OAAO,kBACzH,sBAAMd,EAAGD,EAAMC,EAAI,EAAI4C,GAAS3C,EAAGF,EAAME,EAAEF,EAAMG,EAAE,EAAI,EAAGI,SAAS,UAAnE,SAA8EP,EAAMkD,QAAQvG,OAC5F,sBAAMsD,EAAGD,EAAMC,EAAI4C,EAAQ,GAAKA,GAAS3C,EAAGF,EAAME,EAAEF,EAAMG,EAAE,EAAI,EAAGI,SAAS,UAA5E,oBACA,sBAAON,EAAGD,EAAMC,EAAI4C,GAAS3C,EAAGF,EAAME,EAAEF,EAAMG,EAAE,EAAI,GAAI0C,MAAOA,EAAO7F,OAAO,KAAKoG,MAAO,CAACnC,KAAK,eAC3FoC,QAAS,kBAAMX,GAASD,MAE5B,mBAAGa,QAASA,EAAZ,SACKR,QCmHFS,E,kDAjJX,WAAYvD,GAAO,IAAD,8BACd,cAAMA,IAEDwD,IAAMtC,IAAMuC,YAKjB,EAAKC,aACL,EAAKC,IAAM,EATG,E,yDAYL,IAAD,OACR5I,KAAK6I,IAAM7I,KAAKiF,MAAM6D,kBACtB9I,KAAKK,OAASL,KAAK6I,IAAIxE,eACvBrE,KAAKO,WAAaP,KAAK6I,IAAI5G,OAE3BjC,KAAKC,SAAWD,KAAK6I,IAAIxE,eAAexD,OAExCb,KAAKqE,eAAiB,GACtBrE,KAAK+I,QAAU,GAEf,IAAIC,EAAmB,GAEnBC,EAAU,GAIVC,EAAgBlJ,KAAKiF,MAAMhD,OAAO,GAAY,GAElD,GADGiH,EAAgB,IAAGA,EAAgBlJ,KAAKiF,MAAMhD,QAC5B,IAAlBiH,EAAH,CAEA,IAAI9D,EAAI3F,KAAK0J,IAAI,GAAGD,GAAelJ,KAAKO,WAAW,IACnD6E,EAAE,GAMF,IALA,IAAIgE,GAAMpJ,KAAKiF,MAAM6C,MAAM,GAAI,MAAY9H,KAAKC,SAAS,GACrDoJ,EAAMH,EAAgBlJ,KAAKO,WAE3B+I,EAAQtJ,KAAKO,WAAa8I,EAzBtB,WA2BArI,GACJ,EAAK+H,QAAQ7H,KACT,sBAAMnC,UAAWC,IAAOuK,eAAgBrE,EAAG+D,GAAaG,EAAKpI,EAAIoI,EAAG,EAAIhE,EAAKD,EAAG6D,GAAoBV,QAAS,kBAAK,EAAKrD,MAAM5F,KAAKmK,SAASxI,IAA3I,cAAoJ,YAAYA,KAFhKA,EAAI,EAAGA,EAAIhB,KAAKC,SAAW,EAAGe,IAAK,EAAnCA,GAKR,IAhCQ,eAgCAA,GACJ,EAAK+H,QAAQ7H,KACT,sBAAMnC,UAAWC,IAAOuK,eAAgBrE,EAAG+D,GAAcG,EAAKpI,EAAIoE,EAAKD,EAAG,EAAKF,MAAMhD,OAAS+G,GAAoBV,QAAS,kBAAK,EAAKrD,MAAM5F,KAAKqC,QAAQV,IAAxJ,cAAiK,cAAcA,KAF/KA,EAAI,EAAGA,EAAIhB,KAAKC,SAAW,EAAGe,IAAK,EAAnCA,GAKR,IAAI,IAAIA,EAAI,EAAGA,EAAIhB,KAAKC,SAAUe,IAC9BhB,KAAK+I,QAAQ7H,KACT,cAAC,EAAD,CAAegE,EAAG+D,EAAWG,EAAKpI,EAAIoE,EAAGD,EAAI6D,GAAoB5D,EAAGA,EAChE/F,KAAMW,KAAKiF,MAAM5F,KAAKoK,iBAAiBC,KAAK1J,KAAKgB,GACjD6G,KAAM7H,KAAKiF,MAAM6D,kBAAkB3J,WACnCgJ,QAASnI,KAAKiF,MAAM6D,kBAAkBtE,UAAUxD,IAAS,kBAAkBA,IAOvF,IAFA,IAAI2I,EAAS,GAEL3I,EAAI,EAAGA,EAAIhB,KAAKC,SAAWe,IAAI,CAGnC,IAFA,IAAIF,EAAI,GACJ8I,GAASN,EAAQD,EAAKrJ,KAAKK,OAAOW,GAAGH,QAAQ,EACzCuB,EAAI,EAAGA,EAAIpC,KAAKK,OAAOW,GAAGH,OAAQuB,IAAI,CAC1C,IAAIsB,EAAO1D,KAAKK,OAAOW,GAAGoB,GACvBpB,IAAMhB,KAAKC,SAAS,EACnBa,EAAEI,KAAK,CACHgE,EAAI+D,GAAaG,EAAKpI,EACtBmE,EAAI0E,GAAaD,EAAQP,EAAKjH,EAAI4G,EAClC5D,EAAIA,EACJrE,MAAQ2C,EAAK3C,MAAOM,MAAQqC,EAAKrC,MAAOqB,MAAOgB,EAAKhB,QAExD5B,EAAEI,KAAK,CACHgE,EAAI+D,GAAaG,EAAKpI,EACtBmE,EAAI0E,GAAaD,EAAQP,EAAKjH,EAAI4G,EAClC5D,EAAIA,EACJrE,MAAQ2C,EAAK3C,MAAOM,MAAQqC,EAAKrC,QAE7CsI,EAAOzI,KAAKJ,GAEhBd,KAAKqE,eAAiBsF,K,0CAItB3J,KAAK8J,uBACLC,OAAOC,iBAAiB,SAAUhK,KAAK8J,qBAAqBJ,KAAK1J,S,+EAWjEA,KAAK2I,aACL,IAAItI,EAASL,KAAKqE,eAClBrE,KAAKiK,GAAK,GACV,IAAI,IAAInJ,EAAI,EAAGA,EAAIT,EAAOQ,OAAQC,IAAI,CAClC,GAAGA,EAAIT,EAAOQ,OAAO,EACjB,IAAI,IAAIuB,EAAI,EAAGA,EAAI/B,EAAOS,GAAGD,OAAOuB,IAEhC,IADA,IAAI8H,EAAQ7J,EAAOS,GAAGsB,GACd+H,EAAI,EAAGA,EAAID,EAAMnJ,MAAMF,OAAOsJ,IAAI,CACtC,IAAIC,EAAQ/J,EAAOS,EAAE,GAAGqJ,GACxBnK,KAAKiK,GAAG/I,KACJ,cAAC,EAAD,CACQoF,GAAI4D,EAAMhF,EAAGqB,GAAI2D,EAAM/E,EACvBqB,GAAI4D,EAAMlF,EAAGuB,GAAI2D,EAAMjF,EACvB+B,KAAMiD,EACNhD,MAAO+C,EAAMnJ,MAAMF,OACnB6F,OAAQjH,KAAK4C,MAAuB,IAAjB6H,EAAMnJ,MAAMoJ,IAAW,KALvC,OAAOrJ,EAAEuJ,WAAWjI,EAAEiI,WAAWF,EAAEE,aAW9D,IAAI,IAAIjI,EAAI,EAAGA,EAAI/B,EAAOS,GAAGD,OAAOuB,IAAI,CACpC,IAAI8H,EAAQ7J,EAAOS,GAAGsB,GACtBpC,KAAKiK,GAAG/I,KACJ,cAAC,EAAD,CACIgE,EAAGgF,EAAMhF,EAAGC,EAAG+E,EAAM/E,EAAGC,EAAG8E,EAAM9E,EACjC/D,MAAO5B,KAAK4C,MAAoB,IAAd6H,EAAM7I,OAAc,IACtCqB,MAAOjD,KAAK4C,MAAoB,IAAd6H,EAAMxH,OAAc,IACtCkD,OAAQ5F,KAAK6I,IAAInE,gBAAkB5D,IAAkC,MAA5Bd,KAAK6I,IAAIpE,cAA2BzE,KAAK6I,IAAIpE,eAAiBrC,IAJhG,OAAOtB,EAAEuJ,WAAW,IAAIjI,EAAEiI,cAWjD,OACI,qBAAKtL,UAAWC,IAAOsL,WAAvB,SACI,sBAAKxC,MAAO,OAAQ7F,OAAQ,OAAQwG,IAAKzI,KAAKyI,IAA9C,UACKzI,KAAKiK,GACLjK,KAAK+I,UAF8C,MAAQ/I,KAAK4I,a,GAxIpEzC,IAAMC,WC0CRmE,E,kDAzCX,WAAYtF,GAAO,IAAD,8BACd,cAAMA,IACDuF,MAAM,CACPvI,OAAS,EACT6F,MAAQ,GAJE,E,wDASd,GAAI9H,KAAKyK,WAAT,CACA,IAAMxI,EAASjC,KAAKyK,WAAWC,aAC/B1K,KAAK2K,SAAS,CAAE1I,OAASA,O,iCAGzB,GAAIjC,KAAKyK,WAAT,CACA,IAAM3C,EAAQ9H,KAAKyK,WAAWG,YAC9B5K,KAAK2K,SAAS,CAAE7C,MAAQA,O,0CAIxB9H,KAAK6K,YACL7K,KAAK8K,WACLf,OAAOC,iBAAiB,SAAUhK,KAAK6K,UAAUnB,KAAK1J,OACtD+J,OAAOC,iBAAiB,SAAUhK,KAAK8K,SAASpB,KAAK1J,S,+BAGhD,IAAD,OAEJ,OACI,qBAAKjB,UAAWC,IAAOuL,SAAU9B,IAAM,SAACgC,GAAiB,EAAKA,WAAaA,GAA3E,SACI,cAAC,EAAD,CAAI3B,kBAAmB9I,KAAKiF,MAAM8F,cAAcC,oBAC5CC,IAAKjL,KAAKiF,MAAMgG,IAChBhJ,OAAQjC,KAAKwK,MAAMvI,OAAQ6F,MAAO9H,KAAKwK,MAAM1C,MAC7CzI,KAAMW,KAAKiF,MAAM5F,a,GAnCd8G,IAAMC,W,iBCgDd8E,EAnDG,WAEd,OACI,gCACI,kDACA,kCAAI,gDAAJ,6WAGgC,4CAHhC,+EAIuC,6CAJvC,uEAKC,+CALD,IAMA,uBACA,uBAPA,yHAQsH,sCARtH,wBASM,uCATN,0QAWmB,2CAXnB,IAYA,uBACA,uBAbA,sCAcmC,oDAdnC,4aAkBA,uBACA,uBAnBA,6LAqB0C,6CArB1C,4DAsBA,uBACA,uBAvBA,gFAwB6E,4CAxB7E,kbA4BA,uBA5BA,2CA6BA,uBACA,uBA9BA,gPAgCsG,gDAhCtG,kQAmCA,uBACA,uBApCA,wIAuCA,uBACA,8B,QC7BGC,G,OAbI,SAAClG,GAChB,IAAMmG,EAAYC,MAAMC,QAAQrG,EAAMsG,aAAetG,EAAMsG,YAAc,CAACtG,EAAMsG,aAChF,QAAiBpJ,IAAdiJ,EAAyB,OAAO,KACnC,IAAMI,EAAmBJ,EAAUpD,KAAI,SAACmC,EAAGnJ,GAAJ,OAAU,cAAC,IAAD,CAAeyK,IAAKtB,GAAQnJ,MACzEjC,EAAYkG,EAAMhD,OAAS,GAAK,qBACpC,OACI,qBAAKlD,UAAWA,EAAhB,SACIyM,M,guBCRZ,IAkFeE,EAlFK,WAEhB,IAAIC,EAAqBtI,OAAOC,IAAV,KAClBsI,EAAsBvI,OAAOC,IAAV,KACnBuI,EAAkBxI,OAAOC,IAAV,KACfwI,EAAkBzI,OAAOC,IAAV,KACfyI,EAAkB1I,OAAOC,IAAV,KAEnB,OACI,gCACI,8CACA,mLAE4B,4CAF5B,+BAGI,uBACA,uBAJJ,iBAKkB,4CALlB,iBAKkD,+CALlD,oDAMI,uBANJ,eAOgB,uCAPhB,yKAQ8D,2CAR9D,iFASwC,uCATxC,oDAUI,cAAC,EAAD,CAAYiI,YAAaI,EAAoB1J,QAAQ,IAVzD,kFAWmF,iDAXnF,mDAYQ,uCAZR,iDAYmE,kCAZnE,sBAY8F,kCAZ9F,8EAa0C,kCAb1C,yCAawF,kCAbxF,OAaoG,kCAbpG,6CAca,kCAdb,qBAcuC,kCAdvC,OAcmD,kCAdnD,oBAc4E,kDAd5E,qBAcsH,kCAdtH,mJAgBsB,mDAhBtB,uCAiBI,uBACA,uBAlBJ,wHAmByH,4BAAG,4CAnB5H,WAoBY,4BAAG,4CApBf,kJAqByC,8CArBzC,yCAqBmG,0DArBnG,kHAsBqG,qDAtBrG,IAuBI,uBAvBJ,mHAwBI,uBAxBJ,OAwBa,4BAAG,4CAxBhB,iCAwBkE,kCAxBlE,mCAyBI,cAAC,EAAD,CAAYsJ,YAAaK,EAAqB3J,QAAQ,IACtD,uBA1BJ,mDA2BoD,4BAAG,2CA3BvD,6CA2BoH,4BAAG,4CA3BvH,uEA6BI,+BACI,yCAEI,cAAC,EAAD,CAAYsJ,YAAaM,EAAiB5J,QAAQ,OAEtD,sCAEI,cAAC,EAAD,CAAYsJ,YAAaO,EAAiB7J,QAAQ,OAEtD,sCAEI,cAAC,EAAD,CAAYsJ,YAAaQ,EAAiB9J,QAAQ,UAG1D,uBA3CJ,6DA4C8D,gEA5C9D,uGA8CoC,4CA9CpC,wDA+CI,uBA/CJ,sSAkD0C,mDAlD1C,IAmDI,uBACA,uBApDJ,6DAqD8D,qCArD9D,4BAqDkG,4BAAG,4CArDrG,mUAwDqD,qCAxDrD,qBAwDkF,4BAAG,2CAxDrF,2DAyDa,4BAAG,4CAzDhB,kEA0DI,uBA1DJ,2EA2D4E,oDA3D5E,uCA4DI,gEA5DJ,wIA8DI,uBACA,8B,6tKC5EhB,IA6Ie+J,GA7IS,WACpB,IAAIC,EAAqB5I,OAAOC,IAAV,MAClB4I,EAA2B7I,OAAOC,IAAV,MACxB6I,EAA4B9I,OAAOC,IAAV,MACzB8I,EAAsB/I,OAAOC,IAAV,MACnB+I,EAAmBhJ,OAAOC,IAAV,MAChBc,EAAoBf,OAAOC,IAAV,MACjBgJ,EAA0BjJ,OAAOC,IAAV,MAEvBiJ,EAA0BlJ,OAAOC,IAAV,MACvBkJ,EAA0BnJ,OAAOC,IAAV,MACvBmJ,EAA0BpJ,OAAOC,IAAV,MAEvBoJ,EAAgCrJ,OAAOC,IAAV,MAE7BqJ,EAAyBtJ,OAAOC,IAAV,MACtBsJ,EAAyBvJ,OAAOC,IAAV,KAEtBuJ,EAA0BxJ,OAAOC,IAAV,KAEvBwJ,EAA4BzJ,OAAOC,IAAV,KAIzByJ,EAAiC1J,OAAOC,IAAV,KAE9B0J,EAAe3J,OAAOC,IAAV,KAEZ2J,EAAiC5J,OAAOC,IAAV,KAE9B4J,EAAqB7J,OAAOC,IAAV,KAClB6J,EAAqB9J,OAAOC,IAAV,KAClB8J,EAAqB/J,OAAOC,IAAV,KAClB+J,EAAqBhK,OAAOC,IAAV,KAEtB,OACI,gCACI,kDACA,8BACI,gDADJ,sGAC6H,sCAD7H,+CAEgD,mDAFhD,iHAGoD,kDAHpD,iCAG0G,iDAH1G,0FAKI,kDACA,iDANJ,sHAOQ,wCAPR,mEAOsF,iDAPtF,sFASI,uBATJ,2BAWI,cAAC,EAAD,CAAYiI,YAAaU,EAAoBhK,QAAQ,IACrD,qBAAKqL,IAAKC,8BAA0CC,IAAI,QAAQ1F,MAAM,MAAMO,MAAO,CAACoF,OAAO,OAAOlF,QAAQ,WAZ9G,2LAcsE,2DAdtE,iEAemC,sCAfnC,6NAiBoB,2CAjBpB,oBAkBI,cAAC,EAAD,CAAYgD,YAAaW,EAA0BjK,QAAQ,IAC3D,qBAAKqL,IAAKC,6BAAyCC,IAAI,OAAO1F,MAAM,MAAMO,MAAO,CAACoF,OAAO,OAAOlF,QAAQ,WAnB5G,6IAqBsB,6CArBtB,0FAsBI,cAAC,EAAD,CAAYgD,YAAaY,EAA2BlK,QAAQ,IAtBhE,6aA0B2D,8CA1B3D,IA2BI,uBA3BJ,+RA8BwE,kCA9BxE,IA+BI,cAAC,EAAD,CAAYsJ,YAAaa,EAAqBnK,QAAQ,IA/B1D,6DAgC8D,mDAhC9D,iIAkCI,uBAlCJ,4IAqCI,iDArCJ,gCAsCiC,gDAtCjC,UAuCI,uBAvCJ,2CAwC4C,iDAxC5C,mFAyCO,iDAzCP,mGAyC8H,+CAzC9H,qHA2CI,cAAC,EAAD,CAAYsJ,YAAac,EAAkBpK,QAAQ,IA3CvD,iKA8CI,uBA9CJ,uDA+CwD,6CA/CxD,mCA+C2G,iDA/C3G,gFAiDI,cAAC,EAAD,CAAYsJ,YAAanH,EAAmBnC,QAAQ,IAjDxD,6TAoD+D,2CApD/D,6FAqDI,uBACA,8CAtDJ,0BAuD2B,4CAvD3B,wDAuDkG,0CAvDlG,gDAyDI,cAAC,EAAD,CAAYsJ,YAAae,EAAyBrK,QAAQ,IAzD9D,2FA2DI,uBA3DJ,mEA4DoE,4BAAG,4CA5DvE,kBA6DI,cAAC,EAAD,CAAYsJ,YAAa,CAACgB,EAAwBC,EAAwBC,GAA0BxK,QAAQ,IA7DhH,sCA8DuC,4BAAG,4CA9D1C,4BA8DuF,4BAAG,2CA9D1F,8DA+DiB,oDA/DjB,uBA+D+D,sEA/D/D,IAgEI,cAAC,EAAD,CAAYsJ,YAAamB,EAA+BzK,QAAQ,IAhEpE,kCAiEmC,4BAAG,2CAjEtC,0CAiEgG,uCAjEhG,iHAmEI,cAAC,EAAD,CAAYsJ,YAAa,CAACoB,EAAuBC,GAAyB3K,QAAQ,IAnEtF,6EAoE8E,kCApE9E,SAoE4F,qCApE5F,8BAoEkI,0CApElI,wIAsEY,kCAtEZ,sBAsEuC,2CAtEvC,IAuEI,cAAC,EAAD,CAAYsJ,YAAasB,EAAyB5K,QAAQ,IAE1D,+CAzEJ,WA0EY,8CA1EZ,uLA4EoB,8CA5EpB,2DA4EgG,wDA5EhG,IA6EI,cAAC,EAAD,CAAYsJ,YAAauB,EAA2B7K,QAAQ,IA7EhE,+EA8EgF,6CA9EhF,2CA+EI,4CA/EJ,oHAgFI,cAAC,EAAD,CAAYsJ,YAAawB,EAAgC9K,QAAQ,IAhFrE,+JAkFgB,2CAlFhB,WAkFyC,2CAlFzC,2CAkFkG,4BAAG,2CAlFrG,iBAkFsI,kCAlFtI,+BAmFgC,4BAAG,4CAnFnC,wDAoFI,cAAC,EAAD,CAAYsJ,YAAayB,EAAc/K,QAAQ,IApFnD,0CAqF2C,4BAAG,2CArF9C,4BAqF0F,4BAAG,4CArF7F,YAqF0H,kCArF1H,gDAsFI,uBAtFJ,qHAuFsH,6CAvFtH,mBAyFI,cAAC,EAAD,CAAYsJ,YAAa0B,EAAgChL,QAAQ,IAzFrE,4CA0F6C,yCA1F7C,gHA4FI,0DACA,cAAC,EAAD,CAAYsJ,YAAa,CAAC2B,EAAmBC,EAAmBC,EAAmBC,GAAqBpL,QAAQ,IAChH,uBACA,8BClIHyL,GAAa,CACtB,CACIC,MAAO,eACPC,UAAY,cAAC,EAAD,KAEhB,CACID,MAAO,cACPC,UAAY,cAAC,EAAD,KAEhB,CACID,MAAO,kBACPC,UAAY,cAAC,GAAD,M,oBCYLC,OAxBf,SAAgB5I,GAAO,IAAD,OAClB,SAAS6I,EAAYH,EAAMC,IAEvBtF,EADkBrD,EAAXqD,SACCqF,EAAMC,GAGlB,OACI,8BACI,oBAAI7O,UAAWC,KAAO6O,OAAtB,SACKH,GAAW1F,KAAI,SAAC+F,EAAMpM,GACnB,IAAI5C,EAAYC,KAAOgP,WAIvB,OAHG/I,EAAMkD,UAAY4F,EAAKJ,MACtB5O,GAAa,IAAMC,KAAO6G,SACzB9G,GAAa,IAAMC,KAAOiP,YAE3B,oBAAIlP,UAAWA,EAAuBuJ,QAASwF,EAAYpE,KAAK,EAAKqE,EAAKJ,MAAMI,EAAKH,WAArF,SACQ,+BAAOG,EAAKJ,SADWhM,WCsBxCuM,G,kDAjCX,WAAYjJ,GAAO,IAAD,8BACd,gBACKuF,MAAQ,CACT2D,QAAU,eACVhG,QAAU,cAAC,EAAD,KAJA,E,oDAQVgG,EAAQP,GACZ5N,KAAK2K,SAAS,CACVwD,QAAUA,EACVhG,QAAUyF,M,+BAKd,OACI,sBAAK7O,UAAWC,IAAOoP,kBAAvB,UACI,8BACI,cAAC,GAAD,CAAQ9F,QAAStI,KAAKsI,QAAQoB,KAAK1J,MAAOmI,QAASnI,KAAKwK,MAAM2D,YAElE,qBAAKpP,UAAWC,IAAOqP,kBAAvB,SACI,qBAAKtP,UAAWC,IAAOsP,gBAAvB,SACKtO,KAAKwK,MAAMrC,mB,GAzBZhC,IAAMC,W,oBC0BfmI,OA5Bf,SAAmBtJ,GACf,IAaIuJ,EAbEC,EAAWtI,IAAMuC,YACjBgG,EAAQ,uBAAOjG,IAAKgG,EAAUE,KAAK,OAAOtN,MAAO4D,EAAM5D,MAAOuN,SAAU,SAAAzE,GAAC,OAAIlF,EAAM4J,SAAS1E,EAAE2E,OAAOzN,UAGvG0N,EAAU/P,KAAOgQ,YAAc,IAMnC,OALG/J,EAAMgK,QACLF,GAAW/P,KAAOkQ,YAAc,KACjCjK,EAAMkK,YACLJ,GAAW/P,KAAOoQ,gBAAkB,KAErCnK,EAAMkK,UACE,qBAAKpQ,UAAWgQ,KAGxB9J,EAAMgK,QACLT,EAAS,wBAAQlG,QAAS,kBAAMrD,EAAMoK,UAA7B,gBAEL,sBAAKtQ,UAAWgQ,EAAhB,UACKL,EACAF,OCAFc,OApBf,SAAkBrK,GAEd,IAAI8J,EAAU/P,KAAOgQ,YAAc,IAQnC,OAPG/J,EAAMgK,QACLF,GAAW/P,KAAOkQ,YAAc,KACjCjK,EAAMkK,UACLJ,GAAW/P,KAAOoQ,gBAAkB,IAEpCL,GAAW/P,KAAOuQ,aAAe,IAElCtK,EAAMkK,UACE,qBAAKpQ,UAAWgQ,IAEhB,qBAAKhQ,UAAWgQ,EAAhB,SACK,wBAAQzG,QAAS,kBAAMrD,EAAMoK,UAA7B,kBCwCLG,G,kDAnDX,WAAYvK,GAAO,IAAD,8BACd,cAAMA,IACD2D,IAAM,EAFG,E,qDAKT6G,EAAK9N,EAAMrC,GAChBmQ,EAAK9N,GAASrC,I,+BAKd,IAAImQ,EAAOzP,KAAKiF,MAAMwK,KAClBC,EAAQ,GACRC,EAAe,EACfC,EAAgB,EAChBZ,EAAc,EAClB,GAAGhP,KAAKiF,MAAMgK,MAAM,CAChBS,EAAMxO,KAAK,cAAC,GAAD,CAAiDiO,WAAW,GAA9C,qBAAuBnP,KAAK4I,QACrD,IAAI,IAAIvH,EAAQ,EAAGA,EAAQrB,KAAKiF,MAAM4K,aAAahP,OAAQQ,IACvDqO,EAAMxO,KAAK,cAAC,GAAD,CAAWG,MAAOrB,KAAKiF,MAAM4K,aAAaxO,GAAQgO,OAAQrP,KAAKiF,MAAMoK,OAAOS,GAAGpG,KAAK1J,KAAKqB,GAC5FwN,SAAU7O,KAAKiF,MAAM4J,SAASiB,GAAGpG,KAAK1J,KAAKqB,GAAQ4N,MAAOjP,KAAKiF,MAAMgK,OAChE,iBAAmBU,MAGpCD,EAAMxO,KAAK,cAAC,GAAD,CAAiDiO,WAAW,EAAMF,OAAO,GAA3D,qBAAuBjP,KAAK4I,QACrD,IAAI,IAAIvH,EAAQ,EAAGA,EAAQrB,KAAKiF,MAAM8K,cAAclP,OAAQQ,IACxDqO,EAAMxO,KAAK,cAAC,GAAD,CAAWG,MAAOrB,KAAKiF,MAAM8K,cAAc1O,GAAQgO,OAAQrP,KAAKiF,MAAMoK,OAAOW,IAAItG,KAAK1J,KAAKqB,GAC9FwN,SAAU7O,KAAKiF,MAAM4J,SAASmB,IAAItG,KAAK1J,KAAKqB,GAAQ4N,MAAOjP,KAAKiF,MAAMgK,OACjE,kBAAoBW,UAGpC,CACDF,EAAMxO,KAAK,cAAC,GAAD,CAASmO,OAAQrP,KAAKiF,MAAMgL,aAAkB,qBAAuBjQ,KAAK4I,QACrF,IAAI,IAAIvH,EAAQ,EAAGA,EAAQoO,EAAK5O,OAAQQ,IACpCqO,EAAMxO,KAAK,cAAC,GAAD,CAAWG,MAAOoO,EAAKpO,GAC9BwN,SAAU7O,KAAKiF,MAAM4J,SAASnF,KAAK1J,KAAKqB,GAAQ4N,MAAOjP,KAAKiF,MAAMgK,OAC7D,aAAejP,KAAKiF,MAAMtD,MAAQ,KAAOqN,MAEtDU,EAAMtO,OAAOpB,KAAKiF,MAAMiL,QAAQ,EAAE,EAAE,cAAC,GAAD,CAAWf,WAAW,GAAW,qBAAuBnP,KAAK4I,QAErG,IAAIuH,EAAYnR,KAAO0Q,MAGvB,OAFG1P,KAAKiF,MAAMW,SACVuK,GAAa,IAAMnR,KAAO4G,QAEtB,qBAAK7G,UAAWoR,EAAhB,SACKT,Q,GA/CGvJ,IAAMC,WCsDfgK,G,kDArDX,WAAYnL,GAAO,IAAD,8BACd,gBACK2D,IAAM,EAFG,E,qDAsBd,IAhBA,IAAIyH,EAAO,GAEPC,EAAUtQ,KAAKiF,MAAMqL,QAGrBC,EAAS,cAAC,GAAD,CACDV,aAAc7P,KAAKiF,MAAM4K,aACzBE,cAAe/P,KAAKiF,MAAM8K,cAC1BV,OAAQiB,EAAQjB,OAChBR,SAAUyB,EAAQE,aAClBvB,OAAO,IAGfQ,EAAOzP,KAAKiF,MAAMwK,KAClBS,EAAUlQ,KAAKiF,MAAM4K,aAAahP,OAClC4P,EAAWzQ,KAAKiF,MAAM8K,cAAclP,OAChC6O,EAAQ,EAAGA,EAAQD,EAAK5O,OAAQ6O,IACpCW,EAAKnP,KAAK,cAAC,GAAD,CACEgP,QAASA,EAASO,SAAUA,EAC5BhB,KAAMA,EAAKC,GACX/N,MAAS+N,EACTb,SAAUyB,EAAQI,WAAWhH,KAAK1J,KAAK0P,GACvCO,YAAaK,EAAQK,gBAAgBjH,KAAK1J,KAAK0P,GAC/C9J,OAAU8J,IAAU1P,KAAKiF,MAAM2L,cANjB,cAAgBlB,IAS9C,OACI,sBAAoC3Q,UAAWC,KAAO6R,aAAtD,UACI,sBAAK9R,UAAWC,KAAO8R,eAAvB,UACKP,EACD,qBAAKlI,MAAO,CAAC0I,UAAU,OAAOC,KAAK,WAAWC,UAAU,UAAxD,SACI,qBAAK5I,MAAO,CAAC6I,UAAU,cAAcjP,OAAO,KAA5C,SACKoO,SAIb,sBAAKtR,UAAWC,KAAOmS,uBAAvB,UACI,wBAAQ7I,QAASgI,EAAQc,SAAS1H,KAAK1J,MAAvC,uBACA,wBAAQsI,QAASgI,EAAQe,SAAS3H,KAAK1J,MAAvC,uBACA,wBAAQsI,QAASgI,EAAQgB,UAAU5H,KAAK1J,MAAxC,kC,GA/CGmG,IAAMC,W,oBCqCdmL,OAtCf,SAAkBtM,GACd,IAAMuM,EAAOvM,EAAMuM,KAAOvM,EAAMuM,KAAO,EAQnCC,EAAU,SAACnS,GAIX,MAHkB,QAAf2F,EAAM0J,OACLrP,EAAMG,KAAKwE,IAAI3E,IAEZA,GAbS,EAgBMmI,mBAASxC,EAAM5D,MAAQoQ,EAAQxM,EAAM5D,OAASoQ,GAASxM,EAAMyM,IAAIzM,EAAMkE,KAAK,IAhBlF,mBAgBb9H,EAhBa,KAgBNsQ,EAhBM,OAiBqBlK,mBAASxC,EAAM5D,MAAQ4D,EAAM5D,MAAQA,GAjB1D,mBAiBbuQ,EAjBa,KAiBEC,EAjBF,KAmBhBC,EAAe,SAAC3H,GAChB,IAAI7K,EAAe,IAATkS,EAAaO,SAAS5H,EAAE2E,OAAOzN,OAASuB,WAAWuH,EAAE2E,OAAOzN,OACtEsQ,EAASrS,GACTA,EApBY,SAACA,GAIb,MAHkB,QAAf2F,EAAM0J,OACLrP,EAAMG,KAAKC,IAAIJ,IAEZA,EAgBDiI,CAAUjI,GACHuS,EAAJ,IAATL,EAA6BlS,EAAuBA,EAAI8D,QAAQ,IAC7D6B,EAAM4J,UACL5J,EAAM4J,SAASvP,IAQvB,OALQ,sBAAKP,UAAWC,KAAOgT,eAAvB,UACI,uBAAOrD,KAAK,QAAQxF,IAAKlE,EAAMkE,IAAKuI,IAAKzM,EAAMyM,IAAKrQ,MAAOA,EAAOmQ,KAAMvM,EAAMuM,KAAOvM,EAAMuM,KAAO,EAAGS,MAAM,SAASrD,SAAU,SAACzE,GAAD,OAAO2H,EAAa3H,MAClJ,uBAAM+H,GAAG,YAAYnT,UAAWC,KAAOmT,SAAvC,UAAkDlN,EAAMmN,KAAxD,IAA+DR,SCiThES,G,kDApUX,WAAYpN,GAAO,IAAD,uBACd,cAAMA,IAEDgF,GAAK,IAAIpK,EAAc,EAAE,GAC9B,EAAKyS,gBAAgB,WACrB,IAAIC,EAAkB,GAClBC,EAAkB,GACtB,EAAKC,UAAY,EACjB,EAAKC,WAAa,EAElB,IAAI,IAAK1R,EAAI,EAAGA,EAAI,EAAKiJ,GAAG0I,oBAAoB3R,IAC5CuR,EAAgBrR,KAAK,SAAS,EAAKuR,aAEvC,IAAI,IAAKzR,EAAI,EAAGA,EAAI,EAAKiJ,GAAG2I,qBAAqB5R,IAC7CwR,EAAgBtR,KAAK,UAAU,EAAKwR,cAd1B,OAiBd,EAAKlI,MAAQ,CACTO,cAAgB,EAAKd,GACrBwF,KAAO,CAAC,CAAC,IAAK,GAAI,IAAK,MACvBI,aAAc0C,EACdxC,cAAeyC,GAEnB,EAAKK,iBAvBS,E,6DA2Bd7S,KAAK8S,eAAiB,EACtB9S,KAAK+S,YAAc,I,sCAGPpR,GACZ3B,KAAKiK,GAAG+I,OAAOlO,EAAQnD,M,mCAIvB,IAAI7B,EAAa,KACdE,KAAKwK,MAAMqF,aAAahP,OAAS,IAChCf,EAAaE,KAAKwK,MAAMqF,aAAahP,QACzC,IAAId,EAAc,KACfC,KAAKwK,MAAMuF,cAAclP,OAAS,IACjCd,EAAcC,KAAKwK,MAAMuF,cAAclP,QAC3Cb,KAAKiK,GAAGzJ,eAAeV,EAAWC,GAClCC,KAAKiT,U,oCAILjT,KAAKiK,GAAG3H,YACRtC,KAAKiT,U,qCAGL,IAAItQ,EAAa,KACbE,EAAc,KAKlB,OAJ8B,IAA3B7C,KAAKwK,MAAMiF,KAAK5O,SACf8B,EAAa3C,KAAKwK,MAAMiF,KAAKzP,KAAK+S,aAAaG,MAAM,EAAElT,KAAKwK,MAAMqF,aAAahP,QAC/EgC,EAAc7C,KAAKwK,MAAMiF,KAAKzP,KAAK+S,aAAaG,OAAOlT,KAAKwK,MAAMuF,cAAclP,SAE7E,CAAC8B,EAAYE,K,4CAGpB7C,KAAK8S,cAAgB9S,KAAK+S,YACvB/S,KAAKwK,MAAMiF,KAAK5O,OAAS,IACxBb,KAAK+S,aAAe/S,KAAK+S,YAAY,GAAG/S,KAAKwK,MAAMiF,KAAK5O,U,oCAElD,IAAD,EACuBb,KAAKmT,eAD5B,mBACJxQ,EADI,KACQE,EADR,KAET7C,KAAKoT,sBACLpT,KAAKiK,GAAGxG,YAAYd,EAAWE,GAC/B7C,KAAKiT,U,4CAILjT,KAAK8S,cAAgB9S,KAAK+S,YADT,MAEe/S,KAAKmT,eAFpB,mBAEZxQ,EAFY,KAEAE,EAFA,KAGN7C,KAAKiK,GAAGoJ,oBAAoB1Q,EAAWE,IACzC7C,KAAKoT,sBACdpT,KAAKiT,U,6CAGLjT,KAAK8S,cAAgB9S,KAAK+S,YADR,MAEc/S,KAAKmT,eAFnB,mBAEbxQ,EAFa,KAEDE,EAFC,KAGP7C,KAAKiK,GAAGqJ,qBAAqB3Q,EAAWE,IAC1C7C,KAAKoT,sBACdpT,KAAKiT,U,8BAGD,IAAD,OACHjT,KAAK6S,iBACL,IAAIlQ,EAAa,GACbE,EAAc,GAClB7C,KAAKwK,MAAMiF,KAAK5K,SAAQ,SAAA0O,GACpB5Q,EAAWzB,KAAKqS,EAAEL,MAAM,EAAE,EAAK1I,MAAMqF,aAAahP,SAClDgC,EAAY3B,KAAKqS,EAAEL,OAAO,EAAK1I,MAAMuF,cAAclP,YAEvDb,KAAKiK,GAAGuJ,MAAM7Q,EAAWE,EAAY,KACrC7C,KAAKiT,U,sCAILjT,KAAK8S,cAAgB9S,KAAK+S,YADf,MAEqB/S,KAAKmT,eAF1B,mBAENxQ,EAFM,KAEME,EAFN,KAGM,MAAdF,GAAqC,MAAfE,IACzB7C,KAAKiK,GAAGzG,gBAAgBb,EAAWE,GACnC7C,KAAKoT,sBACLpT,KAAKiT,W,2CAILjT,KAAK8S,cAAgB9S,KAAK+S,YADV,MAEgB/S,KAAKmT,eAFrB,mBAEXxQ,EAFW,KAECE,EAFD,KAGC,MAAdF,GAAqC,MAAfE,IACd7C,KAAKiK,GAAGwJ,qBAAqB9Q,EAAWE,IAC1C7C,KAAKoT,sBACdpT,KAAKiT,W,0CAGLjT,KAAK8S,cAAgB9S,KAAK+S,YADX,MAEiB/S,KAAKmT,eAFtB,mBAEVxQ,EAFU,KAEEE,EAFF,KAGE,MAAdF,GAAqC,MAAfE,IACd7C,KAAKiK,GAAGyJ,oBAAoB/Q,EAAWE,IACzC7C,KAAKoT,sBACdpT,KAAKiT,W,8BAGDzR,GACJxB,KAAKiK,GAAGvI,QAAQF,GAChBxB,KAAKiT,U,+BAGAzR,GACLxB,KAAKiK,GAAGT,SAAShI,GACjBxB,KAAKiT,U,4CAGazR,EAAMI,GACxB5B,KAAKiK,GAAGxI,mBAAmBD,EAAMI,GACjC5B,KAAKiT,U,8BAILjT,KAAK2K,SAAS,CACVI,cAAgB/K,KAAKiK,O,iCAOzB,IAFA,IAAI0J,EAAO3T,KAAKwK,MAAMiF,KAClBmE,EAAY,GACR5S,EAAI,EAAGA,EAAIhB,KAAKwK,MAAMqF,aAAahP,OAASb,KAAKwK,MAAMuF,cAAclP,OAAOG,IAChF4S,EAAU1S,KAAK,GACnByS,EAAKzS,KAAK0S,GACV5T,KAAK2K,SAAS,CAAC8E,KAAOkE,M,iCAGf,IAAD,OACFA,EAAO3T,KAAKwK,MAAMiF,KACtBkE,EAAK9O,SAAQ,SAAAlE,GAAC,OAAIA,EAAES,OAAO,EAAKoJ,MAAMqF,aAAahP,OAAO,EAAE,MAC5D,IAAIgT,EAAW7T,KAAKwK,MAAMqF,aAC1BgE,EAAS3S,KAAK,SAASlB,KAAKyS,aAC5BzS,KAAKiK,GAAG6J,eACR9T,KAAK2K,SAAS,CACVI,cAAgB/K,KAAKiK,GACrBwF,KAAOkE,EACP9D,aAAegE,M,kCAKnB,IAAIF,EAAO3T,KAAKwK,MAAMiF,KACtBkE,EAAK9O,SAAQ,SAAAlE,GAAC,OAAIA,EAAEO,KAAK,MACzB,IAAI2S,EAAW7T,KAAKwK,MAAMuF,cAC1B8D,EAAS3S,KAAK,UAAUlB,KAAK0S,cAC7B1S,KAAKiK,GAAG8J,gBACR/T,KAAK2K,SAAS,CACVI,cAAgB/K,KAAKiK,GACrBwF,KAAOkE,EACP5D,cAAgB8D,M,sCAIRlS,GACZ,IAAIgS,EAAO3T,KAAKwK,MAAMiF,KACtBkE,EAAKvS,OAAOO,EAAM,GAClB3B,KAAK+S,aAAe/S,KAAK+S,YAAY/S,KAAKwK,MAAMiF,KAAK5O,SAASb,KAAKwK,MAAMiF,KAAK5O,OAC3Ec,IAAU3B,KAAK8S,gBACd9S,KAAK8S,eAAiB,GAC1B9S,KAAK2K,SAAS,CACV8E,KAAOkE,M,kCAIHhS,GACR,IAAIgS,EAAO3T,KAAKwK,MAAMiF,KACtBkE,EAAK9O,SAAQ,SAAAlE,GAAC,OAAIA,EAAES,OAAOO,EAAM,MACjC,IAAIkS,EAAW7T,KAAKwK,MAAMqF,aAC1BgE,EAASzS,OAAOO,EAAM,GACtB3B,KAAKiK,GAAG+J,gBAAgBrS,GACxB3B,KAAK2K,SAAS,CACVI,cAAgB/K,KAAKiK,GACrBwF,KAAOkE,EACP9D,aAAegE,M,mCAGVlS,GACT,IAAIgS,EAAO3T,KAAKwK,MAAMiF,KACtBkE,EAAK9O,SAAQ,SAAAlE,GAAC,OAAIA,EAAES,OAAOO,EAAM,MACjC,IAAIkS,EAAW7T,KAAKwK,MAAMuF,cAC1B8D,EAASzS,OAAOO,EAAM,GACtB3B,KAAKiK,GAAGgK,iBAAiBtS,GACzB3B,KAAK2K,SAAS,CACVI,cAAgB/K,KAAKiK,GACrBwF,KAAOkE,EACP5D,cAAgB8D,M,wCAGNxS,EAAM6S,GACpB,IAAIP,EAAO3T,KAAKwK,MAAMqF,aACtB8D,EAAKtS,GAAS6S,EACdlU,KAAK2K,SAAS,CACVkF,aAAe8D,M,yCAGJtS,EAAM6S,GACrB,IAAIP,EAAO3T,KAAKwK,MAAMuF,cACtB4D,EAAKtS,GAAS6S,EACdlU,KAAK2K,SAAS,CACVoF,cAAgB4D,M,iCAGbjE,EAAMrO,EAAM6S,GACnB,IAAIP,EAAO3T,KAAKwK,MAAMiF,KACtBkE,EAAKjE,GAAOrO,GAAS6S,EACrBlU,KAAK2K,SAAS,CACV8E,KAAOkE,M,+BAMN,IAAD,OAGArD,EAAU,CACVe,SAAWrR,KAAKqR,SAAS3H,KAAK1J,MAC9BoR,SAAWpR,KAAKoR,SAAS1H,KAAK1J,MAC9BsR,UAAYtR,KAAKsR,UAAU5H,KAAK1J,MAChCqP,OAAS,CACLS,GAAK9P,KAAKmU,YAAYzK,KAAK1J,MAC3BgQ,IAAMhQ,KAAKoU,aAAa1K,KAAK1J,OAEjCwQ,aAAe,CACXV,GAAK9P,KAAKqU,kBAAkB3K,KAAK1J,MACjCgQ,IAAMhQ,KAAKsU,mBAAmB5K,KAAK1J,OAEvC2Q,gBAAkB3Q,KAAK2Q,gBAAgBjH,KAAK1J,MAC5C0Q,WAAa1Q,KAAK0Q,WAAWhH,KAAK1J,OAElCuU,EAAS,CACT7S,QAAU1B,KAAK0B,QAAQgI,KAAK1J,MAC5BwJ,SAAWxJ,KAAKwJ,SAASE,KAAK1J,MAC9ByJ,iBAAmBzJ,KAAKwU,sBAAsB9K,KAAK1J,OAEvD,OACI,sBAAKjB,UAAWC,IAAOyV,YAAvB,UACI,qBAAK1V,UAAWC,IAAO0V,SAAvB,SACI,cAAC,GAAD,MAEJ,qBAAK3V,UAAWC,IAAO2V,UAAvB,SACI,sBAAKtM,MAAO,CAACE,QAAQ,OAAOqM,cAAc,SAAS5D,KAAK,YAAxD,UACI,qBAAK3I,MAAO,CAACpG,OAAO,MAAMsG,QAAQ,OAAOqM,cAAc,UAAvD,SACI,cAAC,GAAD,CAAUnF,KAAMzP,KAAKwK,MAAMiF,KACfI,aAAc7P,KAAKwK,MAAMqF,aACzBE,cAAe/P,KAAKwK,MAAMuF,cAC1BO,QAASA,EACTM,aAAc5Q,KAAK8S,kBAGnC,sBAAKzK,MAAO,CAACpG,OAAO,MAAMsG,QAAQ,OAAOqM,cAAc,UAAvD,UACI,cAAC,EAAD,CAAU7J,cAAe/K,KAAKwK,MAAMO,cAAeE,IAAKjL,KAAKwK,MAAMS,IAAK5L,KAAMkV,IAC9E,sBAAKxV,UAAWC,IAAO6V,kBAAmBxM,MAAO,CAAC2I,KAAK,YAAvD,UACI,sBAAKjS,UAAWC,IAAO8V,sBAAvB,UACI,wBAAQxM,QAAStI,KAAK+U,YAAYrL,KAAK1J,MAAvC,yBACA,wBAAQsI,QAAStI,KAAKgV,qBAAqBtL,KAAK1J,MAAhD,oCACA,wBAAQsI,QAAStI,KAAKiV,oBAAoBvL,KAAK1J,MAA/C,sCAEJ,sBAAKjB,UAAWC,IAAO8V,sBAAvB,UACI,wBAAQxM,QAAStI,KAAKkV,cAAcxL,KAAK1J,MAAzC,2BACA,wBAAQsI,QAAStI,KAAKmV,mBAAmBzL,KAAK1J,MAA9C,sCACA,wBAAQsI,QAAStI,KAAKoV,kBAAkB1L,KAAK1J,MAA7C,wCAEJ,sBAAKjB,UAAWC,IAAO8V,sBAAvB,UACI,wBAAQxM,QAAStI,KAAKqV,YAAY3L,KAAK1J,MAAvC,uBACA,wBAAQsI,QAAStI,KAAKsV,WAAW5L,KAAK1J,MAAtC,sBACA,wBAAQsI,QAAStI,KAAKwT,MAAM9J,KAAK1J,MAAjC,mBACA,cAAC,GAAD,CACImJ,IAAK,EACLuI,IAAK,IACL/C,KAAK,SACLtN,MAAOrB,KAAKwK,MAAMO,cAAcwK,mBAChC1G,SAAU,SAAC1E,GAAD,OAAO,EAAKK,MAAMO,cAAcyK,iBAAiBrL,IAC3DiI,KAAK,qBACT,cAAC,GAAD,CAAUjJ,KAAM,GACZuI,IAAK,EACLF,KAAM,IACN7C,KAAK,MACLtN,MAAOrB,KAAKwK,MAAMO,cAAc0K,kBAChC5G,SAAU,SAAC1E,GAAD,OAAO,EAAKK,MAAMO,cAAc2K,gBAAgBvL,IAC1DiI,KAAK,wBAIjB,qBAAK/J,MAAO,CAAC2I,KAAK,WAAYD,UAAU,QAAxC,SACI,cAAC,EAAD,CAAYxF,YAAavL,KAAKwK,MAAMO,cAActK,8B,GA1T7D0F,IAAMC,WCAZuP,OATf,WACE,OACE,sBAAK5W,UAAU,MAAMsJ,MAAO,CAACpG,OAAO,QAASsG,QAAQ,OAAS,cAAgB,UAA9E,UACE,cAAC,EAAD,IACA,cAAC,GAAD,QCISqN,GAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,GAAD,MAEFC,SAASC,eAAe,SAM1Bb,M,mBCfAhX,EAAOC,QAAU,CAAC,OAAS,uBAAuB,WAAa,2BAA2B,YAAc,4BAA4B,SAAW,2B,mBCA/ID,EAAOC,QAAU,CAAC,UAAY,wBAAwB,KAAO,mBAAmB,OAAS,qBAAqB,SAAW,yB,mBCAzHD,EAAOC,QAAU,CAAC,QAAU,wBAAwB,eAAe,6BAA6B,aAAe,6BAA6B,gBAAgB,gC,mBCA5JD,EAAOC,QAAU,CAAC,SAAW,2BAA2B,eAAiB,mC","file":"static/js/main.d3ec1cf3.chunk.js","sourcesContent":["// extracted by mini-css-extract-plugin\nmodule.exports = {\"grid_wrapper\":\"DataGrid_grid_wrapper__244vq\",\"grid_container\":\"DataGrid_grid_container__jXyzr\",\"entry\":\"DataGrid_entry__2K7di\",\"active\":\"DataGrid_active__1xSOz\",\"entry_value\":\"DataGrid_entry_value__oKi1E\",\"entry_label\":\"DataGrid_entry_label__1_qD-\",\"entry_separator\":\"DataGrid_entry_separator__2Cz9e\",\"entry_button\":\"DataGrid_entry_button__3kMeX\",\"grid_container_buttons\":\"DataGrid_grid_container_buttons__IWFi9\"};","// extracted by mini-css-extract-plugin\nmodule.exports = {\"splitScreen\":\"Layout_splitScreen__1IutT\",\"leftPane\":\"Layout_leftPane__kbmS8\",\"leftPane_content_wrapper\":\"Layout_leftPane_content_wrapper__37c12\",\"content_wrapper\":\"Layout_content_wrapper__2_XKn\",\"InfoPanel_wrapper\":\"Layout_InfoPanel_wrapper__1g6lB\",\"InfoPanel_content\":\"Layout_InfoPanel_content__GHD45\",\"leftPane_content\":\"Layout_leftPane_content__28MIS\",\"rightPane\":\"Layout_rightPane__3z6oq\",\"rightPane_section\":\"Layout_rightPane_section__1QR0L\",\"buttons_container\":\"Layout_buttons_container__WKhKc\",\"div_buttons_container\":\"Layout_div_buttons_container__14b2V\",\"lower_buttons_container\":\"Layout_lower_buttons_container__2c14K\"};","// extracted by mini-css-extract-plugin\nmodule.exports = {\"VisualNN\":\"VisualNN_VisualNN__2VnbU\",\"svgWrapper\":\"VisualNN_svgWrapper__1wKYA\",\"addLayerButton\":\"VisualNN_addLayerButton__3mRF3\",\"activation_opt\":\"VisualNN_activation_opt__1AxW-\",\"opt_active\":\"VisualNN_opt_active__iPL_g\"};","\r\n\r\nimport styles from './Navbar.module.css';\r\n\r\nconst Navbar = () => {\r\n\r\n  return (\r\n    <div className={styles._navbar}>\r\n      <div className={styles._navbar_left}>\r\n        Neural Network Visualizer\r\n      </div>\r\n    </div>\r\n  );\r\n}\r\n\r\nexport default Navbar;","let activation = {\r\n    linear : {\r\n        func : (val) => val,\r\n        deriv : (val) => 1\r\n    },\r\n    sigm : {\r\n        func : (val) => 1 / (1 + Math.exp(-val)),\r\n        deriv : (val) => val * (1-val)\r\n    },\r\n    relu : {\r\n        func : (val) => val > 0 ? val : 0,\r\n        deriv : (val) => val > 0 ? 1 : 0\r\n    },\r\n    relu2 : {\r\n        func : (val) => val > 0 ? val : 0.1*val,\r\n        deriv : (val) => val > 0 ? 1 : 0.1\r\n    }\r\n}\r\n\r\nexport default activation","import activation from \"./activation\"\r\n\r\nexport default class NeuralNetwork{\r\n    constructor(input_size,output_size){\r\n        \r\n        this.n_layers = 3;\r\n\r\n        this.bias = true;\r\n\r\n        this.learning_rate = 0.02;\r\n        this.training_times = 200;\r\n        \r\n        this.layers = [];\r\n        this.layer_activation = []\r\n        this.max_height = 0;\r\n\r\n        this.createRandomNN(input_size,output_size);\r\n\r\n        this.expression = []\r\n\r\n        this.action = \"\";\r\n    }\r\n\r\n    getTrainingTimes(){\r\n        return this.training_times;\r\n    }\r\n    setTrainingTimes(t){\r\n        this.training_times = t\r\n    }\r\n    getLearningRate(){\r\n        return this.learning_rate;\r\n    }\r\n    setLearningRate(lr){\r\n        this.learning_rate = lr\r\n    }\r\n\r\n    getInputLayerSize(){\r\n        if(this.bias)\r\n            return this.layers[0].length - 1;\r\n        return this.layers[0].length;\r\n    }\r\n\r\n    getOutputLayerSize(){\r\n        return this.layers[this.layers.length-1].length;\r\n    }\r\n\r\n    getLayerSize(l){\r\n        if(l === this.layers.length-1)\r\n            return this.layers[l].length;\r\n        if(this.bias)\r\n            return this.layers[l].length - 1;\r\n        return this.layers[l].length;\r\n    }\r\n\r\n    addInputNode(){\r\n        let edges = [];\r\n        for(let i = 0; i < this.getLayerSize(1);i++){\r\n            edges.push(Math.random());\r\n        }\r\n        this.layers[0].splice(this.getLayerSize(0),0,{value : NaN, edges : edges, edges_old : [...edges]});\r\n        if(this.layers[0].length > this.max_height)\r\n            this.max_height = this.layers[0].length;\r\n    }\r\n\r\n    addOutputNode(){\r\n        for(let  i = 0; i < this.layers[this.layers.length-2].length;i++){\r\n            this.layers[this.layers.length-2][i].edges.push(Math.random());\r\n        }\r\n        this.layers[this.layers.length-1].push({value : NaN, edges : [1]});\r\n        if(this.layers[this.layers.length-1].length > this.max_height)\r\n            this.max_height = this.layers[this.layers.length-1].length;\r\n    }\r\n    addNode(layer){\r\n        for(let  i = 0; i < this.layers[layer-1].length;i++){\r\n            this.layers[layer-1][i].edges.push(Math.random());\r\n        }\r\n        let edges = [];\r\n        for(let i = 0; i < this.getLayerSize(layer+1); i++){\r\n            edges.push(Math.random());\r\n        }\r\n        this.layers[layer].splice(this.getLayerSize(layer),0,{value : NaN, edges : edges, edges_old : [...edges]});\r\n        if(this.layers[layer].length > this.max_height)\r\n            this.max_height = this.layers[layer].length;\r\n    }\r\n\r\n    addLayer(layer){\r\n        for(let i = 0; i < this.layers[layer].length;i++){\r\n            this.layers[layer][i].edges = [];\r\n        }\r\n        this.layers.splice(layer+1,0,[]);\r\n        if(this.bias){\r\n            let edges = [];\r\n            for(let i = 0; i < this.getLayerSize(layer+2); i++){\r\n                edges.push(Math.random());\r\n            }\r\n            this.layers[layer+1].push({value : 1, edges : edges , edges_old : [...edges]});\r\n\r\n        }\r\n        this.layer_activation.splice(layer+1,0,null);\r\n        this.setLayerActivation(layer+1,\"sigm\");\r\n        this.addNode(layer+1);\r\n    }\r\n\r\n    deleteInputNode(index){\r\n        this.layers[0].splice(index,1);\r\n        this.max_height = 0;\r\n        for(let i = 0; i < this.layers.length;i++)\r\n            if(this.layers[i].length > this.max_height)\r\n                this.max_height = this.layers[i].length\r\n    }\r\n    deleteOutputNode(index){\r\n        for(let  i = 0; i < this.layers[this.layers.length-2].length;i++){\r\n            this.layers[this.layers.length-2][i].edges.splice(index,1);\r\n        }\r\n        this.layers[this.layers.length-1].splice(index,1);\r\n        this.max_height = 0;\r\n        for(let i = 0; i < this.layers.length;i++)\r\n            if(this.layers[i].length > this.max_height)\r\n                this.max_height = this.layers[i].length\r\n    }\r\n\r\n    setLayerActivation(layer,name){\r\n        if(!activation.hasOwnProperty(name)) return;\r\n        this.layer_activation[layer] = {name : name, activation : activation[name]}\r\n    }\r\n\r\n\r\n    resetVars(){\r\n        this.step_layer = null;\r\n        this.step_node = null;\r\n    }\r\n\r\n    createRandomNN(input_size,output_size){\r\n        this.resetVars();\r\n        this.layers = [];\r\n        this.max_height = 0;\r\n        for(let l = 0; l < this.n_layers; l++){\r\n            let layer = [];\r\n            let height = Math.floor(Math.random() * 3) + 2;\r\n            //let height = 2;\r\n            if(l === 0 && input_size !== null && input_size !== undefined)\r\n                height = input_size\r\n            if(l === this.n_layers-1 && output_size !== null && output_size !== undefined)\r\n                height = output_size\r\n            for(let n = 0; n < height; n++){\r\n                layer.push({value : Math.round(Math.random()*1000)/1000, edges : []});\r\n            }\r\n            if(this.bias && l !== this.n_layers-1)\r\n                layer.push({value : 1, edges : []});\r\n            if(layer.length > this.max_height) this.max_height = layer.length;\r\n            this.layers.push(layer);\r\n            this.setLayerActivation(l,\"sigm\");\r\n        }\r\n        this.randomize()\r\n    }\r\n\r\n    randomize(){\r\n        this.resetVars();\r\n        for(let l = 0; l < this.layers.length; l++){\r\n            for(let n = 0; n < this.layers[l].length; n++){\r\n                this.layers[l][n].edges = [];\r\n                if(l === this.layers.length-1)\r\n                    this.layers[l][n].edges.push(1);\r\n                else{\r\n                    let size = this.layers[l+1].length;\r\n                    if(l+1 < this.layers.length - 1 && this.bias) size -= 1\r\n                    for(let n2 = 0; n2 < size; n2++)\r\n                        this.layers[l][n].edges.push(Math.random());\r\n                    this.layers[l][n].edges_old = this.layers[l][n].edges\r\n                }\r\n            }\r\n        }\r\n        this.clearNodes();\r\n    }\r\n\r\n    clearNodes(){\r\n        for(let l = 0; l < this.layers.length; l++){\r\n            let size = this.layers[l].length;\r\n            if(l < this.layers.length-1 && this.bias) size -= 1\r\n            for(let n = 0; n < size; n++){\r\n                this.layers[l][n].value = NaN;\r\n                this.layers[l][n].error = NaN;\r\n            }\r\n        }\r\n    }\r\n    setInputLayer(input_data){\r\n        if(input_data != null){\r\n            for(let i = 0; i < input_data.length;i++){\r\n                this.layers[0][i].value = parseFloat(input_data[i]);\r\n            }\r\n        }\r\n    }\r\n\r\n    feedforward(input_data, output_data){\r\n        this.setInputLayer(input_data)\r\n        for(let l = 1; l < this.layers.length; l++){\r\n            //let layer = this.layers[l];\r\n            let layer_prev = this.layers[l-1];\r\n            let activation = this.layer_activation[l].activation.func\r\n            for(let n = 0; n < this.getLayerSize(l); n++){\r\n                let sum = 0;\r\n                for(let prev_n = 0; prev_n < layer_prev.length;prev_n++){\r\n                    sum+= layer_prev[prev_n].value * layer_prev[prev_n].edges[n];\r\n                }\r\n                this.layers[l][n].value = activation(sum);\r\n            }\r\n        }\r\n        //let error = 0;\r\n        if(output_data != null){\r\n            let last = this.layers.length-1;\r\n            for(let i = 0; i < this.layers[last].length; i++){\r\n                this.layers[last][i].error = this.layers[last][i].value - output_data[i];\r\n                //error += this.layers[last][i].error * this.layers[last][i].error;\r\n            }\r\n        }\r\n\r\n    }\r\n\r\n    feedforwardStepNode(input_data, output_data){\r\n        \r\n        this.expression = []\r\n        if(this.step_node == null || this.action !== \"feedforward\"){\r\n            this.action = \"feedforward\"\r\n            this.step_node = 0;\r\n            this.clearNodes();\r\n            this.setInputLayer(input_data);\r\n            if(this.step_layer == null)\r\n                this.step_layer = 1;\r\n            return false;\r\n        }\r\n        let layer_prev = this.layers[this.step_layer-1];\r\n        let sum = 0;\r\n\r\n        let in_expression = '';\r\n        in_expression += `in_${this.step_node}^${this.step_layer}=`\r\n\r\n        for(let prev_n = 0; prev_n < layer_prev.length;prev_n++){\r\n            in_expression += layer_prev[prev_n].value.toFixed(4) + \"*\" + layer_prev[prev_n].edges[this.step_node].toFixed(4)\r\n            if(prev_n !== layer_prev.length - 1)\r\n                in_expression +=\"+\"\r\n            sum+= layer_prev[prev_n].value * layer_prev[prev_n].edges[this.step_node];\r\n        }\r\n        in_expression += \" = \" + sum.toFixed(4);\r\n        this.expression.push(String.raw`${in_expression}`)\r\n\r\n        let out_expression = \"\"\r\n        this.layers[this.step_layer][this.step_node].value = this.layer_activation[this.step_layer].activation.func(sum);\r\n        out_expression += `out_${this.step_node}^${this.step_layer}=activation(in_${this.step_node}^${this.step_layer})=`+ this.layer_activation[this.step_layer].name +\"(\" + sum.toFixed(4) + \")=\" + this.layers[this.step_layer][this.step_node].value.toFixed(4)\r\n\r\n        this.expression.push(String.raw`${out_expression}`)\r\n\r\n        this.step_node++;\r\n        if(this.step_node >= this.getLayerSize(this.step_layer)){\r\n            this.step_node = 0;\r\n            this.step_layer++;\r\n        }\r\n        if(this.step_layer >= this.layers.length){\r\n            this.step_layer = null;\r\n            this.step_node = null;\r\n            this.action = \"\"\r\n            return true;\r\n        }\r\n        return false;\r\n    }\r\n\r\n    feedforwardStepLayer(input_data, output_data){\r\n        this.expression = []\r\n        if(this.step_layer == null || this.action !== \"feedforward\"){\r\n            this.action = \"feedforward\"\r\n            this.step_layer = 1;\r\n            this.clearNodes();\r\n            this.setInputLayer(input_data);\r\n            return false;\r\n        }\r\n        \r\n        //let layer = this.layers[this.step_layer];\r\n        let layer_prev = this.layers[this.step_layer-1];\r\n        let n = (this.step_node == null) ? 0 : this.step_node;\r\n        let activation = this.layer_activation[this.step_layer].activation.func\r\n        for(; n < this.getLayerSize(this.step_layer); n++){\r\n            let sum = 0;\r\n            for(let prev_n = 0; prev_n < layer_prev.length;prev_n++){\r\n                sum+= layer_prev[prev_n].value * layer_prev[prev_n].edges[n];\r\n            }\r\n            this.layers[this.step_layer][n].value = activation(sum);\r\n        }\r\n        this.step_layer++;\r\n        \r\n        if(this.step_layer >= this.layers.length){\r\n            this.step_layer = null;\r\n            this.step_node = null;\r\n            this.action = \"\"\r\n            return true;\r\n        }\r\n        return false;\r\n    }\r\n\r\n    train(input_data, output_data){\r\n        this.expression = []\r\n        for(let t = 0; t < this.training_times; t++)\r\n            for(let i = 0; i < input_data.length; i++)\r\n                this.backpropagation(input_data[i],output_data[i]);\r\n    }\r\n\r\n    backpropagation(input_data, output_data){\r\n        this.feedforward(input_data,output_data);\r\n        let last = this.layers.length-1;\r\n        for(let i = 0; i < this.layers[last].length;i++){\r\n            let node = this.layers[last][i];\r\n            node.derivative = this.layer_activation[0].activation.deriv(node.value) * node.error;\r\n        }\r\n        for(let l = last-1; l >= 0; l--){\r\n            let size_layer = this.layers[l].length;\r\n            let derivative = this.layer_activation[l].activation.deriv\r\n            for(let i = 0; i < size_layer; i++){\r\n                let node = this.layers[l][i];\r\n                let d_sum = 0;\r\n                for(let a = 0; a < node.edges.length;a++){\r\n                    d_sum += this.layers[l][i].edges[a] * this.layers[l+1][a].derivative;\r\n                }\r\n                node.derivative = d_sum * derivative(node.value);\r\n            }\r\n        }\r\n        for(let l = last-1; l >= 0; l--){\r\n            let size_layer = this.layers[l].length;\r\n            for(let i = 0; i < size_layer; i++){\r\n                let node = this.layers[l][i];\r\n                for(let a = 0; a < node.edges.length;a++){\r\n                    if(!isFinite(node.edges[a])) continue;\r\n                    node.edges[a] -= node.value * this.layers[l+1][a].derivative * this.learning_rate;\r\n                    console.log(node.edges[a]);\r\n                }\r\n            }   \r\n        }\r\n    }\r\n\r\n    backpropagationLayer(input_data, output_data){\r\n        this.expression = []\r\n        if(this.step_layer == null || this.action !== \"backpropagation\"){\r\n            this.action = \"backpropagation\"\r\n            this.feedforward(input_data,output_data);\r\n            this.step_layer = this.layers.length-1;\r\n            return false;\r\n        }\r\n        let prev_layer = this.step_layer - 1;\r\n\r\n        if(this.step_layer === this.layers.length-1){\r\n            for(let i = 0; i < this.layers[this.step_layer].length;i++){\r\n                let node = this.layers[this.step_layer][i];\r\n                node.derivative = this.layer_activation[0].activation.deriv(node.value) * node.error;\r\n            }\r\n        }else{\r\n            let size_layer = this.layers[this.step_layer].length;\r\n            let derivative = this.layer_activation[this.step_layer].activation.deriv\r\n            for(let i = 0; i < size_layer; i++){\r\n                let node = this.layers[this.step_layer][i];\r\n                let d_sum = 0;\r\n                for(let a = 0; a < node.edges.length;a++){\r\n                    d_sum += this.layers[this.step_layer][i].edges_old[a] * this.layers[this.step_layer+1][a].derivative;\r\n                }\r\n                node.derivative = d_sum * derivative(node.value);\r\n            }\r\n        }\r\n\r\n        let size_layer = this.layers[prev_layer].length;\r\n        for(let i = 0; i < size_layer; i++){\r\n            let node = this.layers[prev_layer][i];\r\n            for(let a = 0; a < node.edges.length;a++){\r\n                if(!isFinite(node.edges[a])) continue;\r\n                node.edges_old[a] = node.edges[a];\r\n                node.edges[a] -= node.value * this.layers[this.step_layer][a].derivative * this.learning_rate;\r\n                console.log(node.edges[a])\r\n            }\r\n        }\r\n\r\n        this.step_layer--;\r\n        if(this.step_layer <= 0){\r\n            this.step_layer = null;\r\n            this.step_node = null;\r\n            this.action = \"\"\r\n            return true;\r\n        }\r\n        return false;\r\n    }\r\n\r\n    backpropagationNode(input_data, output_data){\r\n        this.expression = []\r\n        if(this.step_node == null || this.action !== \"backpropagation\"){\r\n            this.action = \"backpropagation\"\r\n            this.feedforward(input_data,output_data);\r\n            this.step_node = 0;\r\n            if(this.step_layer == null)\r\n                this.step_layer = this.layers.length-1;\r\n            return false;\r\n        }\r\n        \r\n        let node_expression = String.raw`\\Delta `;\r\n        node_expression += `node^${this.step_layer}_${this.step_node} = `\r\n\r\n        let prev_layer = this.step_layer - 1;\r\n\r\n        if(this.step_layer === this.layers.length-1){\r\n            \r\n            let node = this.layers[this.step_layer][this.step_node];\r\n            node.derivative = this.layer_activation[0].activation.deriv(node.value) * node.error;\r\n            node_expression += this.layer_activation[0].activation.deriv(node.value).toFixed(4) + \"*\" + node.error.toFixed(4)\r\n            node_expression += \"=\" + node.derivative.toFixed(4)\r\n        }else{\r\n            let derivative = this.layer_activation[this.step_layer].activation.deriv\r\n            \r\n            let node = this.layers[this.step_layer][this.step_node];\r\n            let d_sum = 0;\r\n            node_expression += \"(\"\r\n            for(let a = 0; a < node.edges.length;a++){\r\n                d_sum += this.layers[this.step_layer][this.step_node].edges_old[a] * this.layers[this.step_layer+1][a].derivative;\r\n                node_expression += this.layers[this.step_layer+1][a].derivative.toFixed(4) + \"*\" + this.layers[this.step_layer][this.step_node].edges_old[a].toFixed(4)\r\n                if(a !== node.edges.length - 1) node_expression += \"+\"\r\n            }\r\n            node_expression += \")\"\r\n            node.derivative = d_sum * derivative(node.value);\r\n            node_expression += \"*\" + derivative(node.value).toFixed(4)\r\n            node_expression += \"=\" + node.derivative.toFixed(4)\r\n        }\r\n        this.expression.push(node_expression)\r\n        \r\n        let size_layer = this.layers[prev_layer].length;\r\n        for(let i = 0; i < size_layer; i++){\r\n            let weight_expression = \"\";\r\n            let node = this.layers[prev_layer][i];\r\n            \r\n            if(!isFinite(node.edges[this.step_node])) continue;\r\n            node.edges_old[this.step_node] = node.edges[this.step_node];\r\n            node.edges[this.step_node] -= node.value * this.layers[this.step_layer][this.step_node].derivative * this.learning_rate;\r\n            console.log(node.edges[this.step_node])\r\n            weight_expression += `weight_{${i},${this.step_node}}^${prev_layer}=` + node.edges_old[this.step_node].toFixed(4) + \"-\" + this.learning_rate.toFixed(4) + \"*\" + this.layers[this.step_layer][this.step_node].derivative.toFixed(4) + \"*\" + node.value.toFixed(4)\r\n            weight_expression += \"=\" + node.edges[this.step_node].toFixed(4)\r\n            this.expression.push(weight_expression)\r\n        }\r\n        \r\n\r\n        this.step_node++;\r\n        if(this.step_node >= this.getLayerSize(this.step_layer)){\r\n            this.step_node = 0;\r\n            this.step_layer--;\r\n        }\r\n        if(this.step_layer <= 0){\r\n            this.step_layer = null;\r\n            this.step_node = null;\r\n            this.action = \"\"\r\n            return true;\r\n        }\r\n        return false;\r\n\r\n    }\r\n\r\n\r\n    getRepresentation(){\r\n        return {\r\n            representation : this.layers,\r\n            height : this.max_height,\r\n            activation : Object.keys(activation),\r\n            layer_act : this.layer_activation,\r\n            current_node : this.step_node,\r\n            current_layer : this.step_layer,\r\n        }\r\n    }\r\n\r\n    export(){\r\n        let obj = {\r\n            learning_rate : this.learning_rate,\r\n            bias : this.bias\r\n        };\r\n        let weights = [];\r\n        this.layers.forEach(layer =>{\r\n            let l = [];\r\n            layer.forEach(node => l.push(node.edges))\r\n            weights.push(l);\r\n        })\r\n        obj.weights = weights\r\n        return obj;\r\n    }\r\n\r\n    import(obj){\r\n        this.layers = []\r\n        this.max_height = 0;\r\n        this.bias = obj.bias\r\n        this.learning_rate = obj.learning_rate\r\n        obj.weights.forEach(layer =>  {\r\n            let l = [];\r\n            layer.forEach(edges =>{\r\n                let node = {edges:edges,edges_old:[...edges]};\r\n                if(this.bias && l.length === layer.length-1 && this.layers.length !== obj.weights.length-1)\r\n                    node.value = 1;\r\n                l.push(node)\r\n            })\r\n            this.layers.push(l)\r\n            if(layer.length > this.max_height) this.max_height = layer.length\r\n        })\r\n        this.n_layers = this.layers.length\r\n    }\r\n\r\n\r\n}\r\n","let samples = {\r\n\r\n    sample1 : {\r\n        \"learning_rate\": 0.5,\r\n        \"bias\": true,\r\n        \"weights\": [\r\n          [\r\n            [\r\n              0.15,\r\n              0.25\r\n            ],\r\n            [\r\n              0.2,\r\n              0.3\r\n            ],\r\n            [\r\n              0.35,\r\n              0.35\r\n            ]\r\n          ],\r\n          [\r\n            [\r\n              0.4,\r\n              0.5\r\n            ],\r\n            [\r\n              0.45,\r\n              0.55\r\n            ],\r\n            [\r\n              0.6,\r\n              0.6\r\n            ]\r\n          ],\r\n          [\r\n            [\r\n              1\r\n            ],\r\n            [\r\n              1\r\n            ]\r\n          ]\r\n        ]\r\n      }\r\n\r\n}\r\n\r\n\r\n\r\nexport default samples;","import React from 'react';\r\n\r\nimport styles from './Node.module.css'\r\n\r\nclass Node extends React.Component{\r\n\r\n    constructor(props){\r\n        super(props);\r\n        this.x = props.x ? props.x : 50;\r\n        this.y = props.y ? props.y : 50;\r\n        this.r = props.r ? props.r : 25;\r\n    }\r\n\r\n\r\n    render(){\r\n        let value_text = \"\";\r\n        if((this.props.value && !isNaN(this.props.value)) || this.props.value === 0)\r\n            value_text = <text /*className={styles.node_data}*/ x={this.x} y={this.y} \r\n                            textAnchor=\"middle\" fontSize=\"smaller\">v:{this.props.value}</text>\r\n        let error_text = \"\";\r\n        if(this.props.error && !isNaN(this.props.error))\r\n            error_text = <text /*className={styles.node_data}*/ x={this.x} y={this.y+this.r/2} \r\n                            textAnchor=\"middle\" fontSize=\"smaller\">e:{this.props.error}</text>\r\n        let isActiveClass = styles.circle + \" \" + (this.props.active ? styles.isActive : \"\")\r\n        return (\r\n            <g className={styles.node}>\r\n                <circle className={isActiveClass} cx={this.x} cy={this.y} r={this.r} stroke=\"black\" strokeWidth=\"2\" fill=\"white\" />\r\n                {value_text}\r\n                {error_text}\r\n            </g>\r\n        )\r\n    }\r\n}\r\n\r\nexport default Node;","import React from 'react';\r\n\r\nclass Edge extends React.Component{\r\n\r\n    constructor(props){\r\n        super();\r\n        this.x1 = props.x1 ? props.x1 : 50;\r\n        this.y1 = props.y1 ? props.y1 : 50;\r\n        this.x2 = props.x2 ? props.x2 : 100;\r\n        this.y2 = props.y2 ? props.y2 : 100;\r\n        this.weight = props.weight ? props.weight : undefined;\r\n    }\r\n\r\n    render(){\r\n        let r = Math.hypot(this.y1-this.y2,this.x1-this.x2);\r\n        let angle = Math.atan2(this.y2-this.y1,this.x2-this.x1)\r\n        let inter = function(a,b,r1,r2,t){ \r\n                        return r1 + (t-a)/(b-a)*(r2-r1)\r\n                    }\r\n        let n_r = inter(-Math.PI/2, Math.PI/2,0,r, angle)\r\n        n_r = (this.props.dest+1)/(this.props.total+2)*r*1.3\r\n        let middle = {x : this.x1 + n_r*Math.cos(angle), y : this.y1 + n_r*Math.sin(angle)}\r\n        angle = angle * 180 / Math.PI;\r\n        //console.log(n_r,middle,angle);\r\n        let transform = `rotate(${angle}, ${middle.x}, ${middle.y})`;\r\n        return (\r\n            <g>\r\n                <line x1={this.x1} y1={this.y1} x2={this.x2} y2={this.y2} stroke=\"black\" />\r\n                <text x={middle.x} y={middle.y - 10} textAnchor=\"middle\" fontSize=\"smaller\" transform={transform} >{this.weight}</text>\r\n            </g>\r\n            \r\n            \r\n        )\r\n\r\n    }\r\n\r\n}\r\n\r\nexport default Edge;","import React , { useState } from 'react';\r\n\r\nimport styles from './VisualNN.module.css'\r\n\r\nconst LayerDropDown  = (props) => {\r\n\r\n    const [open, setOpen] = useState(false);\r\n\r\n    const options = props.opts\r\n\r\n    const width = 50;\r\n\r\n    let entries = options.map((opt,i) => {\r\n        //let color = opt === props.current.name ? \"#c5d3ee\" : \"rgb(255,255,255)\"\r\n        let className = styles.activation_opt + \" \"\r\n        className += opt === props.current.name ? styles.opt_active : \"\"\r\n        return (\r\n            <g key={\"drop_opt_\"+i}>\r\n                <rect className={className} x={props.x - width/2} y={props.y+props.r/2 + 15 * i} width={width} height=\"15\"\r\n                    style={{stroke:\"rgb(0, 0, 0)\"}}/>\r\n                <text x={props.x + 2 - width/2} y={props.y+props.r/2 + 15 * (i+1) - 2} fontSize=\"smaller\">{opt}</text>\r\n                <rect  x={props.x - width/2} y={props.y+props.r/2 + 15 * i} width={width} height=\"15\"\r\n                    style={{fill:\"transparent\"}}\r\n                    onClick={() => {props.func(opt);setOpen(false)}}/>\r\n            </g>\r\n        )\r\n    })\r\n\r\n    let display = open ? \"block\" : \"none\"\r\n    \r\n    return (\r\n        <g>\r\n            <rect  x={props.x - width/2} y={props.y+props.r/2 - 15} width={width} height=\"15\" style={{fill:\"rgb(255,255,255)\",stroke:\"rgb(0, 0, 0)\"}}/>\r\n            <text x={props.x + 2 - width/2} y={props.y+props.r/2 - 2} fontSize=\"smaller\">{props.current.name}</text>\r\n            <text x={props.x + width - 13 - width/2} y={props.y+props.r/2 - 3} fontSize=\"x-small\"></text>\r\n            <rect  x={props.x - width/2} y={props.y+props.r/2 - 15} width={width} height=\"15\" style={{fill:\"transparent\"}}\r\n                onClick={() => setOpen(!open)}\r\n            />\r\n            <g display={display}>\r\n                {entries}\r\n            </g>\r\n        </g>\r\n    )\r\n    \r\n}\r\n\r\nexport default LayerDropDown;","import React from 'react';\r\nimport Node from './Node/Node';\r\nimport Edge from './Edge/Edge';\r\nimport LayerDropDown from './LayerDropDown'\r\n\r\nimport styles from './VisualNN.module.css'\r\n\r\nclass NN extends React.Component{\r\n\r\n    constructor(props){\r\n        super(props);\r\n\r\n        this.ref = React.createRef()\r\n\r\n        /*this.height = props.height !== undefined ? props.height : 400;\r\n        this.width = props.width ? props.width : 700;*/\r\n        \r\n        this.buildModel();\r\n        this.key = 0\r\n    }\r\n\r\n    buildModel(){\r\n        this.rep = this.props.neuralNetwork_rep\r\n        this.layers = this.rep.representation;\r\n        this.max_height = this.rep.height;\r\n        \r\n        this.n_layers = this.rep.representation.length;\r\n\r\n        this.representation = []\r\n        this.buttons = []\r\n\r\n        let buttonsDivHeight = 30;\r\n\r\n        let marginx = 50;\r\n        let marginy = 10;\r\n        \r\n        \r\n        let usable_height = this.props.height-2*marginy - 2 * buttonsDivHeight;\r\n        if(usable_height < 0) usable_height = this.props.height;\r\n        if(usable_height === 0) return\r\n\r\n        let r = Math.min(30,usable_height/(this.max_height+2))-5;\r\n        r=25\r\n        let dx = (this.props.width-2*r-2*marginx)/(this.n_layers-1);\r\n        let dy = (usable_height)/(this.max_height);\r\n\r\n        let max_h = this.max_height * dy;\r\n\r\n        for(let i = 0; i < this.n_layers - 1; i++){\r\n            this.buttons.push(\r\n                <text className={styles.addLayerButton} x={marginx+ r + dx * i + dx/2 - r/5} y={buttonsDivHeight/2} onClick={()=> this.props.func.addLayer(i)} key={'buttonup_'+i}>+</text>\r\n            )\r\n        }\r\n        for(let i = 1; i < this.n_layers - 1; i++){\r\n            this.buttons.push(\r\n                <text className={styles.addLayerButton} x={marginx + r + dx * i - r/5} y={this.props.height - buttonsDivHeight/2} onClick={()=> this.props.func.addNode(i)} key={'buttondown_'+i}>+</text>\r\n            )\r\n        }\r\n        for(let i = 1; i < this.n_layers; i++){\r\n            this.buttons.push(\r\n                <LayerDropDown x={marginx  + dx * i + r} y={ buttonsDivHeight/2} r={r}\r\n                    func={this.props.func.changeActivation.bind(this,i)}\r\n                    opts={this.props.neuralNetwork_rep.activation}\r\n                    current={this.props.neuralNetwork_rep.layer_act[i]} key={'layer_dropDown_'+i}\r\n                    />\r\n            )\r\n        }\r\n\r\n        let nn_rep = []\r\n\r\n        for(let i = 0; i < this.n_layers ; i++){\r\n            let l = [];\r\n            let space = (max_h - dy * this.layers[i].length)/2;\r\n            for(let n = 0; n < this.layers[i].length; n++){\r\n                let node = this.layers[i][n];\r\n                if(i === this.n_layers-1)\r\n                    l.push({\r\n                        x : marginx+ r + dx * i ,\r\n                        y : marginy+ r + space + dy * n + buttonsDivHeight,\r\n                        r : r ,\r\n                        edges : node.edges, value : node.value, error: node.error})\r\n                else\r\n                    l.push({\r\n                        x : marginx+ r + dx * i ,\r\n                        y : marginy+ r + space + dy * n + buttonsDivHeight,\r\n                        r : r ,\r\n                        edges : node.edges, value : node.value})\r\n            }\r\n            nn_rep.push(l)\r\n        }\r\n        this.representation = nn_rep\r\n    }\r\n\r\n    componentDidMount(){\r\n        this.updateRepresentation();\r\n        window.addEventListener('resize', this.updateRepresentation.bind(this));\r\n    }\r\n    updateRepresentation(){\r\n        //if(this.ref == null || this.ref.current == null) return;\r\n        /*this.width = this.ref.current.clientWidth;\r\n        this.forceUpdate()*/\r\n    }\r\n\r\n\r\n    render(){\r\n        //console.log(this.props.height);\r\n        this.buildModel();\r\n        let layers = this.representation\r\n        this.nn = [];\r\n        for(let l = 0; l < layers.length; l++){\r\n            if(l < layers.length-1){\r\n                for(let n = 0; n < layers[l].length;n++){\r\n                    let node1 = layers[l][n];\r\n                    for(let e = 0; e < node1.edges.length;e++){\r\n                        let node2 = layers[l+1][e];\r\n                        this.nn.push(\r\n                            <Edge key={\"Edge\"+l.toString()+n.toString()+e.toString()} \r\n                                    x1={node1.x} y1={node1.y}\r\n                                    x2={node2.x} y2={node2.y}\r\n                                    dest={e}\r\n                                    total={node1.edges.length}\r\n                                    weight={Math.round(node1.edges[e] * 1000)/1000}\r\n                            />\r\n                        )\r\n                    }\r\n                }\r\n            }\r\n            for(let n = 0; n < layers[l].length;n++){\r\n                let node1 = layers[l][n];\r\n                this.nn.push(\r\n                    <Node key={\"Node\"+l.toString()+\",\"+n.toString()} \r\n                        x={node1.x} y={node1.y} r={node1.r} \r\n                        value={Math.round(node1.value * 1000)/1000}\r\n                        error={Math.round(node1.error * 1000)/1000}\r\n                        active={this.rep.current_layer === l && (this.rep.current_node ==    null || this.rep.current_node === n )}\r\n                        />\r\n                    )\r\n            }\r\n\r\n        }\r\n        \r\n        return (\r\n            <div className={styles.svgWrapper}>\r\n                <svg width={'100%'} height={'100%'} ref={this.ref} key={\"svg\" + this.key++}>\r\n                    {this.nn}\r\n                    {this.buttons}\r\n                </svg>\r\n            </div>\r\n        )\r\n\r\n    }\r\n\r\n}\r\n\r\nexport default NN;","import React from 'react';\r\n\r\nimport NN from '../Visual/NN'\r\n\r\nimport styles from './VisualNN.module.css'\r\n\r\nclass VisualNN extends React.Component{\r\n\r\n    constructor(props){\r\n        super(props);\r\n        this.state={\r\n            height : 0,\r\n            width : 0\r\n        }\r\n    }\r\n\r\n    setHeight(){\r\n        if(!this.divElement) return;\r\n        const height = this.divElement.clientHeight;\r\n        this.setState({ height : height });  \r\n    }\r\n    setWidth(){\r\n        if(!this.divElement) return;\r\n        const width = this.divElement.clientWidth;\r\n        this.setState({ width : width });  \r\n    }\r\n\r\n    componentDidMount() {\r\n        this.setHeight();\r\n        this.setWidth();\r\n        window.addEventListener('resize', this.setHeight.bind(this))\r\n        window.addEventListener('resize', this.setWidth.bind(this))\r\n    }\r\n\r\n    render(){\r\n        //console.log(this.state.height)\r\n        return (\r\n            <div className={styles.VisualNN} ref={ (divElement) => { this.divElement = divElement }}>\r\n                <NN neuralNetwork_rep={this.props.neuralNetwork.getRepresentation()} \r\n                    num={this.props.num} \r\n                    height={this.state.height} width={this.state.width}\r\n                    func={this.props.func}/>\r\n            </div>\r\n            \r\n        )\r\n    }\r\n\r\n}\r\n//<NN neuralNetwork_rep={this.props.neuralNetwork.getRepresentation() } num={this.props.num}></NN>\r\nexport default VisualNN;","import React from 'react';\r\n\r\n\r\nconst InfoBasic = () => {\r\n\r\n    return (\r\n        <div>\r\n            <h3>Neural Networks </h3>\r\n            <p> <b>Neural Networks</b> (NN) are inspired by our brains and how they work. Just like our brains NN are composed\r\n            by series of layers of interconnected (artificial) neurons that send their signals to the next neurons and so on.\r\n            The artificial neurons process the signals it receives and then forwards the processed value to the neurons in the next layer.\r\n            The first layer in known as the <b>input layer</b> where we supply the initial values,\r\n            whereas the last layer is known as the <b>output layer</b> where we get the final values. The intermediate layers are known as \r\n             <b> hidden layers</b>.\r\n            <br/>\r\n            <br/>\r\n            A Neural Networks can be consisted of several layer of different number of neurons. Neurons or nodes are connected by <b>edges</b> and each edge\r\n            has a <b>weight</b> associated, which represent how much the value of the origin neuron influences the value in the end neuron. This\r\n            weight is adjusted during the training phase and by adjusting the weights we can make our inputs match the correspondent outputs,\r\n            or at least make a <b>prediction</b>.\r\n            <br/>\r\n            <br/>\r\n            Neural Networks are mainly used in <b>supervised learning</b> tasks, where we give the input and the correspondent output and our model\r\n            tries to fit the training data, so our model will be a function that maps the input values to output values. Our goal is that our\r\n            model can generalize even to unseen data and correctly predict the output. It is called supervised learning because we feed the input\r\n            and we supervise the output, adjusting until we can achieve an acceptable performance.\r\n            <br/>\r\n            <br/>\r\n            In the Neural Network model we try to achieved nodes or a set of nodes that can recognize certain patterns in our data and activate uppon that.\r\n            This behaviour arise throught the complex <b>interactions</b> between the previous nodes by the edges connecting them.\r\n            <br/>\r\n            <br/>\r\n            The process of transforming and processing the inputs into outputs is called <b>feedforward</b>, where we feed our neural network\r\n            with the input values. Each value is passed to the nodes in the next layer through the edges, stronger edges have greater influence\r\n            in the next nodes. However a neuron might not be activated by small enough values of the predecessors, which means that neuron will\r\n            not contribute to the next layer, to accomplish this when need to process the values recevied, this is known as activation function.\r\n            <br/>More on feedforward on the next section.\r\n            <br/>\r\n            <br/>\r\n            To make our inputs match the outputs we have to adjust the weights in each edge, by strengthening or weakening the edge, thus changing\r\n            the contribution of each node in order to achieve the desired result. We do this with a method called <b>backpropagation</b>,\r\n            where we try to minimize the error between the predicted value and the output one, in the last layer, and make small, incremental changes\r\n            in the weights so that the error is a little smaller than previously. We then propagate backwards this calculation.\r\n            <br/>\r\n            <br/>\r\n            Here we are going to focus on the basis of neural networks and on the most commum and basic layouts. \r\n            More details in a next sections.\r\n            <br/>\r\n            <br/>\r\n            </p>\r\n        </div>\r\n    );\r\n}\r\n\r\nexport default InfoBasic;\r\n","import { MathComponent } from 'mathjax-react'\r\n\r\nimport React from 'react';\r\n\r\nimport './Expression.css'\r\n\r\nconst Expression = (props) => {\r\n    const equations = Array.isArray(props.expressions) ? props.expressions : [props.expressions]\r\n    if(equations === undefined) return null;\r\n    const typesetEquations = equations.map((e, i) => <MathComponent tex={e} key={i} />);\r\n    let className = props.height ? \"\" : \"expression_wrapper\"\r\n    return (\r\n        <div className={className}>\r\n           {typesetEquations} \r\n        </div>\r\n        \r\n    );\r\n}\r\n\r\nexport default Expression;","import React from 'react';\r\nimport Expression from '../Expression/Expression';\r\n\r\n\r\n\r\nconst FeedForward = () => {\r\n    //let expression = [];\r\n    let node_in_expression = String.raw`in_i^l = \\sum_{k=1} out_k^{l-1} \\times w_{k,i}`;\r\n    let node_out_expression = String.raw`out_i^l = activation(in_i^l)`;\r\n    let sigm_expression = String.raw`sig(x)= \\frac{1}{1 + e^{-x}}`;\r\n    let tanh_expression = String.raw`tanh(x)= \\frac{e^x - e^{-x}}{e^x + e^{-x}}`;\r\n    let relu_expression = String.raw`relu(x)= \\cases { x  & if  x >= 0 \\cr 0 &  if x < 0  }`;\r\n    //expression.push(node_expression)\r\n    return (\r\n        <div>\r\n            <h3>FeedForward </h3>\r\n            <p>\r\n                First we need to understand how we transform inputs into output, how the processing of data is made throughout our model.\r\n                This process is know as <b>feedforward</b>, so let's see how it works!\r\n                <br/>\r\n                <br/>\r\n                First, in the <b>input layer</b> we place our <b>initial values</b>, we are feeding the input values to the network.\r\n                <br/>\r\n                Now we must <b>foward</b> the input value through the model. For this, each node from the next layer will compute its value from the\r\n                previous layer. So each node from the previous layer will <b>contribute</b> partly to each neuron on the next layer,\r\n                this contribution is defined by the <b>weight</b>. So the calculation for each node is as follows:\r\n                <Expression expressions={node_in_expression} height={true}/>\r\n                This expression allows us to get a representation, a value, which contains the <b>agregated values</b> of the previous layer, taking into account\r\n                the <b>weight</b> of each edge between the nodes. We take node <i>n</i> and for each node <i>k</i> from the previous layer, we the sum\r\n                the multiplication of each value node <i>k</i> by the weight of the edge connecting <i>k</i> to <i>n</i>. The multiplication of the node\r\n                value of <i>k</i> by the weight of <i>k</i> to <i>n</i> gives us of the <b>node contribution</b>, where that node <i>k</i>,\r\n                has a higher contribution to nodes where the edge is greater, and smaller where the node is smaller. This operation of sum,\r\n                then gives us the <b>total contribution</b> of the previous layer to this node.\r\n                <br/>\r\n                <br/>\r\n                However we need to model how the node will react to this value we have calculated. This operation will transform our <b><i>in value </i></b>\r\n                into an <b><i>out value</i></b>, which will be what the node is going to fire to the next layer. In some sense, comparing to our brains,\r\n                it decides whether the neuron should <b>activate/fire</b> or not. This operation is helpful in <b>detecting useful patterns</b> in our data,\r\n                allowing a node or a set of nodes, to understand the data behaviour. This process is makes us of <b>activation functions</b>.\r\n                <br/> In most cases we use non-linear functions, in order to model more complex and non-linear problems and patterns.\r\n                <br/>The <b><i>out value</i></b>, or the output value of node <i>n</i> takes the following expression:\r\n                <Expression expressions={node_out_expression} height={true}/>\r\n                <br/>\r\n                As we can see, we apply a transformation to our <b><i>in value</i></b> we calculated previously, and we get the <b><i>out value</i></b>.\r\n                The activation function can take may forms but the most usual are:\r\n                <ul>\r\n                    <li>\r\n                        Sigmoid\r\n                        <Expression expressions={sigm_expression} height={true}/>\r\n                    </li>\r\n                    <li>\r\n                        Tanh\r\n                        <Expression expressions={tanh_expression} height={true}/>\r\n                    </li>\r\n                    <li>\r\n                        RELU\r\n                        <Expression expressions={relu_expression} height={true}/>\r\n                    </li>\r\n                </ul>\r\n                <br/>\r\n                We do the feedfoward through the entire network, from the <b>input layer to the output layer</b>, layer by layer, and the final\r\n                result will be in the output layer.\r\n                This final results are known as <b>predictions</b> of our network given the correspondent input values.\r\n                <br/>\r\n                This process of computing the out values, from the in values, from the out values of the previous layer can be seen as complex\r\n                multidimensional composite function, because we are applying a function to the result of applying another function and so on.\r\n                So we can see our neural network as a <b>composite function</b>.\r\n                <br/>\r\n                <br/>\r\n                To get better results we can implement something known as <b>bias</b>, in which we add to the <b><i>in values</i></b> of each layer or even node,\r\n                a constant, fixed amount, which will act as shift in the activation function, allowing us to get a more complex behaviour.\r\n                This shift will be constant to every input values and won't change the slop or format of the activation function, only \r\n                moving it to the right or left. In the case of a <i>tanh</i>, when we have an <b><i>in value</i></b> of 0, if we apply a bias of -5, instead of 0,\r\n                we get a <b><i>out value</i></b> very close to 1, shifting the activation function to the left.\r\n                <br/>\r\n                This can be achieved by introducing a node in the previous layer with a <b>constant value of 1</b>, and the bias is represented in the\r\n                <b> weights of the the connections</b> between this newly added node and the destination nodes, which means the contribution, bias, equals\r\n                to the weight of the connection.\r\n                <br/>\r\n                <br/>\r\n            </p>\r\n\r\n            \r\n        </div>\r\n    );\r\n}\r\n\r\nexport default FeedForward;\r\n","import React from 'react';\r\nimport Expression from '../Expression/Expression';\r\n\r\nconst Backpropagation = () => {\r\n    let example_expression = String.raw`f(x) = x^2`;\r\n    let example_deriv_expression = String.raw`f'(x) = 2x`;\r\n    let basic_gradient_expression = String.raw`x^{t+1} =  x^t - f'(x)`;\r\n    let gradient_expression = String.raw`x_j^{t+1} =  x_j^t - \\alpha \\frac{\\partial f}{\\partial x_j}`;\r\n    let error_expression = String.raw`Error = \\frac 1 2 \\sum_{i=1} (out_i^{last} - actual_i)^2`;\r\n    let weight_expression = String.raw`w_{k,i}^{t+1} =  w_{k,i}^t - \\alpha \\frac{\\partial E}{\\partial w_{k,i}}`;\r\n    let error_weight_expression = String.raw`\\frac{\\partial E}{\\partial w_{k,n}} = \\frac{\\partial E}{\\partial out_n^{last}} \\times \\frac{\\partial out_n^{last}}{\\partial in_n^{last}} \\times \\frac{\\partial in_n^{last}}{\\partial w_{k,n}}`;\r\n    \r\n    let error_node_expression_1 = String.raw`\\frac{\\partial E}{\\partial out_n^{last}} = \\frac {\\partial \\frac 1 2 \\sum_{n=1} (out_n^{last} - actual_n)^2} {\\partial out_n^{last}}`\r\n    let error_node_expression_2 = String.raw`= 2 \\times \\frac 1 2 \\times (out_n^{last} - actual_n)^{2-1} \\times - 1`\r\n    let error_node_expression_3 = String.raw`= actual_n-out_n^{last}`\r\n\r\n    let activation_deriv_expression_1 = String.raw`\\frac{\\partial out_n^{last}}{\\partial in_n^{last}} = \\frac{\\partial activation(in_n^{last})}{\\partial in_n^{last}} = activation'(in_n^{last})`\r\n    \r\n    let weight_in_expression_1 = String.raw`\\frac{\\partial in_n^{last}}{\\partial w_{k,n}} = \\frac{\\partial \\sum_{k=1} out_k^{last-1} \\times w_{k,n}}{\\partial w_{k,n}}`\r\n    let weight_in_expression_2 = String.raw`= out_k^{last-1}`\r\n\r\n    let node_delta_expression_2 = String.raw` \\Delta node_n^{last} = \\frac{\\partial E}{\\partial out_n^{last}} \\times \\frac{\\partial out_n^{last}}{\\partial in_n^{last}} = \\frac{\\partial E}{\\partial in_n^{last}}`\r\n    \r\n    let error_weight_expression_2 = String.raw`\\frac{\\partial E}{\\partial w_{k,n}} = \\frac{\\partial E}{\\partial out_n^l} \\times \\frac{\\partial out_n^l}{\\partial in_n^l} \\times \\frac{\\partial in_n^l}{\\partial w_{k,n}}`;\r\n\r\n    //let error_weight_expression_2 = String.raw`\\frac{\\partial E}{\\partial w_{k,n}} = \\frac{\\partial E}{\\partial out_n} \\times \\frac{\\partial out_n}{\\partial in_n} \\times \\frac{\\partial in_n}{\\partial w_{k,n}}`;\r\n\r\n    let error_hidden_node_expression_1 = String.raw`\\frac{\\partial E}{\\partial out_n^l} = \\sum_{k=1} { \\left( \\frac{\\partial E}{\\partial in_k^{l+1}} \\frac{\\partial in_k^{l+1}}{\\partial out_n^l} \\right) } `\r\n\r\n    let weight_deriv = String.raw`\\frac{\\partial in_k^{l+1}}{\\partial out_n^l} = w_{n,k}`\r\n \r\n    let error_hidden_node_expression_2 = String.raw`\\frac{\\partial E}{\\partial out_n^l} = \\sum_{k=1} { \\left( \\Delta node_k^{l+1} \\times w_{n,k} \\right) }`\r\n\r\n    let final_expression_1 = String.raw` \\Delta node_n^{last} = (actual_n-out_n^{last}) \\times activation'(node_n^{last})`\r\n    let final_expression_2 = String.raw` \\Delta node_n^{l} = \\sum_{k=1} { \\left( \\Delta node_k^{l+1} \\times w_{n,k} \\right) } \\times activation'(node_n^l)`\r\n    let final_expression_3 = String.raw` \\Delta w_{n,k} = \\Delta node_n^{l} \\times out_n^{l-1}`\r\n    let final_expression_4 = String.raw` w_{n,k}^{t+1} = w_{n,k}^{t} \\times \\alpha \\space \\Delta w_{n,k}`\r\n\r\n    return (\r\n        <div>\r\n            <h3>Backpropagation </h3>\r\n            <p>\r\n                <b>Backpropagation</b> is one of the most important things in Neural Networks, it is the method that allows our model to <b>train</b>\r\n                and fit to the data we feed. Our goal is to <b>change each weight</b> in the network, so that the predictions of the network match\r\n                the real outputs. The trick here is to apply an <b>iterative process</b> that will try, step by step, <b>minize the error</b> of the model. Before diving\r\n                into the process itself we need to understand some things.\r\n                <h4>Gradient descent</h4>\r\n                <b>Gradient descent</b> is one of the key methods of backpropagation, it is an iterative optimization algorithm, where we try to find\r\n                the <b>minimum</b> of a function. The principle here is to try to give successive <b>descendent steps</b>, from a starting point,\r\n                until we can get the minimum point. But how do we do this?\r\n                <br/>\r\n                Lets take this function:\r\n                <Expression expressions={example_expression} height={true}/>\r\n                <img src={process.env.PUBLIC_URL + \"/imgs/x^2.png\"} alt=\"y=x^2\" width='40%' style={{margin:'auto',display:'block'}}/>\r\n                We can see that our minimum point is at x = 0, which is also the global minimum, the lower point across all function.\r\n                But how do he get there starting from somewhere? We can imagine a <b>ball rolling down the hill</b>, and we take a step into that\r\n                direction, so depending on the <b>slope</b> of the fuction we make our move to the next point, and we repeat the process.\r\n                In this example, for values of x less than 0 we go right, for values of x greater than 0 we go left. This notion of slopes\r\n                takes us to the <b>derivative</b> of the function:\r\n                <Expression expressions={example_deriv_expression} height={true}/>\r\n                <img src={process.env.PUBLIC_URL + \"/imgs/2x.png\"} alt=\"y=2x\" width='40%' style={{margin:'auto',display:'block'}}/>\r\n                As we can see, the derivative gives us the slope in the ascendent direction, however, if we take a step in the opposite\r\n                direction we will <b>drive closer</b> to a minimum or an approximation of it. Note that this only works in convex functions.\r\n                <Expression expressions={basic_gradient_expression} height={true}/>\r\n                But we are not done yet, sometimes we can take a step in one direction and we when end up further away from the minimum than\r\n                initialy, so we define a step size, with which we multiply our jump. But how big enough should the step size be? We cannot\r\n                know exatcly how big it should be but we make a guess, given it is smaller than the optimal one, to avoid moving away from\r\n                the minimum. This is a defined parameter, known as the <b>learning rate</b>.\r\n                <br/>\r\n                Furthermore, we can apply this principal to each of the dimension of the function, for every variable. If we have a function\r\n                which takes more then one variable, we can apply this method to each one of the variables.\r\n                This gives us the following update expression, for each variable in <i>f</i>: \r\n                <Expression expressions={gradient_expression} height={true}/>\r\n                For those not familiar with that expression, it means the <b>partial derivative</b> of the function with respect to a variable, in other\r\n                words, how much the function changes in terms of that specific variable.\r\n                <br/>\r\n                By an iterative approach, repeting this process, we can sucessfully get to a set variable that is more and more close to a \r\n                local minimum.\r\n                <h4>Backpropagation</h4>\r\n                Now we are ready to know how <b>Backpropagation</b> works!\r\n                <br/>\r\n                For backpropagation we are going to use <b>gradient descent</b>, but what function are we trying to find the minimum of? Well, we are going\r\n                to <b>minize the error</b> between the prediction and the actual output. And the set of variables we are updating are the <b>set of weights</b> of\r\n                our network model, in order to have the lowest error. For convinience we define the error function as follows:\r\n                <Expression expressions={error_expression} height={true}/>\r\n                This function is convex and allows us to differentiate so that the constants cancel out, that's why it turns out useful to define\r\n                the error function this way.\r\n                <br/>\r\n                We will consider two cases, the base case being the <b>output layer</b>, and the second case being the <b>remaining layers</b>.\r\n                As we seen before, we want to update our weights following this expression:\r\n                <Expression expressions={weight_expression} height={true}/>\r\n                But how do we calculate that gradient? We cannot directly calculate that value, but there is a way. As we seen in the previous section,\r\n                our model can be seen as composite function and  our error function is just being applyed to the results of our model,\r\n                making it also a composite function as well. So we can the <b>chain rule</b>, which allows us to decompose a derivative into several simpler, computable, derivatives.\r\n                <br/>\r\n                <h5>Output Layer</h5>\r\n                So, let's start by the <b>first layer</b> (output layer), and then propagate this calculation <b>backwards</b>. For the first layer we can get\r\n                the follows: \r\n                <Expression expressions={error_weight_expression} height={true}/>\r\n                We can calculte each of this subexpressions, so we are going to walk through one by one.\r\n                <br/>\r\n                The first part means how much the error changes in terms of the <b><i>out value</i></b>  in each node.\r\n                <Expression expressions={[error_node_expression_1,error_node_expression_2,error_node_expression_3]} height={true}/>\r\n                The second part means how much the <b><i>out value</i></b> changes in terms of the <b><i>in value</i></b>. We know that the out value is calculated by\r\n                applying the <b>activation function</b>, so we can use the <b>derivative of the activation function</b>.\r\n                <Expression expressions={activation_deriv_expression_1} height={true}/>\r\n                The third part is how much the <b><i>in value</i></b> changes in terms of the correspondent <b>weight</b>. We know how the in value is calculated,\r\n                the first part of the feedfoward, so we can calculate this gradient:\r\n                <Expression expressions={[weight_in_expression_1,weight_in_expression_2]} height={true}/>\r\n                One thing we can notice is that for every edge that goes to the same node <i>n</i>, the <b>only</b> thing that changes is the <b>last term</b>,\r\n                which turns out to depend on the origin node. This value can, then, be saved to be used for updating each weight that goes\r\n                to node <i>n</i>, we call this the <b>node delta</b>:\r\n                <Expression expressions={node_delta_expression_2} height={true}/>\r\n                \r\n                <h5>Hidden layers</h5>\r\n                For the <b>hidden layers</b>, we go from the last layer and work our way to the first and apply a similar process.\r\n                We want to know how much a weight influences the total error, but this time,\r\n                a weight in the <b>hidden layers</b>, will have influence not only in one output values but <b>every output layer node</b>.\r\n                <Expression expressions={error_weight_expression_2} height={true}/>\r\n                The first part here is different here because we must take into account the <b>contribution</b> of the hidden node to every node in the\r\n                <b> next layer</b>. So, we must sum the contributions to the error on the nodes in ht next layer. We get the following expression :\r\n                <Expression expressions={error_hidden_node_expression_1} height={true}/>\r\n                As we can see, each term of the sumation sequence will be composed of two parts, the first one, we have calculated before and saved that value,\r\n                this is the <b>node delta</b> of the <b>next layer</b>, and second expression is how much the <b><i>in value</i></b> of some node <i>k</i>\r\n                changes with respect to the <b><i>out value</i></b> the previous layer, which can be defined as follows:\r\n                <Expression expressions={weight_deriv} height={true}/>\r\n                We can see that this works because the <b><i>in value</i></b> of a node only uses the <b><i>out value</i></b> of node <i>n</i> multiplying by the weight of the connection.\r\n                <br/>\r\n                So, putting this all together, our final expression for how much the error changes in terms of the out value of a <b>hidden node </b>\r\n                is the follwing:\r\n                <Expression expressions={error_hidden_node_expression_2} height={true}/>\r\n                The remaing expressions are deducted the <b>same way</b> as the output layer, so they stay the same, and the node delta can be calculated with this newly \r\n                expression.\r\n                <h5>Wrapping it all together</h5>\r\n                <Expression expressions={[final_expression_1,final_expression_2,final_expression_3,final_expression_4]} height={true}/>\r\n                <br/>\r\n                <br/>\r\n            </p>\r\n\r\n            \r\n        </div>\r\n    );\r\n}\r\n\r\nexport default Backpropagation;","import InfoBasic from \"../../Info/InfoBasic\";\r\n//import Feedback from \"../../Info/Feedback\";\r\nimport FeedForward from \"../../Info/FeedForward\";\r\nimport Backpropagation from \"../../Info/Backpropagation\";\r\n\r\n\r\nexport const TopbarData = [\r\n    {\r\n        title: 'Introduction',\r\n        component : <InfoBasic/> \r\n    },\r\n    {\r\n        title: 'Feedforward',\r\n        component : <FeedForward/>\r\n    },\r\n    {\r\n        title: 'Backpropagation',\r\n        component : <Backpropagation/>  \r\n    },\r\n    /*{\r\n        title: 'Activation Functions',\r\n        component : <Feedback/>\r\n    },\r\n    {\r\n        title: 'Data',\r\n        component : <Feedback/>\r\n    },*/\r\n\r\n]","import React from 'react'\r\nimport { TopbarData } from './TopbarData'\r\n\r\nimport styles from './Topbar.module.css'\r\n\r\nfunction Topbar(props){\r\n    function handleClick(title,component) {\r\n        const {onClick} = props;\r\n        onClick(title,component);\r\n    }\r\n\r\n    return ( \r\n        <nav>\r\n            <ul className={styles.Topbar}>\r\n                {TopbarData.map((item, index) => {\r\n                    let className = styles.TopbarItem;\r\n                    if(props.current === item.title)\r\n                        className += \" \" + styles.isActive;\r\n                    else className += \" \" + styles.isNotActive;\r\n                    return(\r\n                        <li className={className} key={index} onClick={handleClick.bind(this,item.title,item.component)}>\r\n                                <span>{item.title}</span>\r\n                        </li>\r\n                    )\r\n                })}\r\n            </ul>\r\n        </nav>\r\n    )\r\n}\r\nexport default Topbar","import React from 'react';\r\nimport InfoBasic from '../Info/InfoBasic';\r\n\r\nimport styles from './Layout.module.css'\r\nimport Topbar from './Topbar/Topbar';\r\n\r\n\r\nclass InfoPanel extends React.Component{\r\n\r\n    constructor(props){\r\n        super();\r\n        this.state = {\r\n            tabName : 'Introduction',\r\n            current : <InfoBasic/>\r\n        }\r\n    }\r\n\r\n    onClick(tabName,component){\r\n        this.setState({\r\n            tabName : tabName,\r\n            current : component\r\n        })\r\n    }\r\n\r\n    render(){\r\n        return (\r\n            <div className={styles.InfoPanel_wrapper}>\r\n                <div>\r\n                    <Topbar onClick={this.onClick.bind(this)} current={this.state.tabName}/>\r\n                </div>\r\n                <div className={styles.InfoPanel_content    }>\r\n                    <div className={styles.content_wrapper}>\r\n                        {this.state.current}\r\n                    </div>\r\n                </div>\r\n            </div>\r\n            \r\n        )\r\n    }\r\n\r\n}\r\n\r\nexport default InfoPanel;\r\n\r\n\r\n/*\r\n<div className={styles.leftPane_content_wrapper}>\r\n                <Topbar onClick={this.onClick.bind(this)} current={this.state.tabName}/>\r\n                <div className={styles.content_wrapper}>\r\n                    {this.state.current}\r\n                </div>\r\n            </div>\r\n*/","import React from 'react';\r\n\r\nimport styles from './DataGrid.module.css'\r\n\r\n\r\nfunction DataValue(props){\r\n    const inputRef=  React.createRef();\r\n    const input = <input ref={inputRef} type=\"text\" value={props.value} onChange={e => props.callback(e.target.value)}/>;\r\n\r\n    let display;\r\n    let class_n = styles.entry_value + \" \"\r\n    if(props.label)\r\n        class_n += styles.entry_label + \" \"\r\n    if(props.separator)\r\n        class_n += styles.entry_separator + \" \"\r\n\r\n    if(props.separator)\r\n        return <div className={class_n}/>\r\n\r\n    let button\r\n    if(props.label)\r\n        button = <button onClick={() => props.remove()}>X</button>\r\n    display = (\r\n            <div className={class_n}>\r\n                {input}\r\n                {button}\r\n            </div>\r\n            )\r\n\r\n\r\n    return display\r\n\r\n}\r\nexport default DataValue;","import React from 'react';\r\n\r\nimport styles from './DataGrid.module.css'\r\n\r\n\r\nfunction DataAux (props){\r\n\r\n    let class_n = styles.entry_value + \" \"\r\n    if(props.label)\r\n        class_n += styles.entry_label + \" \"\r\n    if(props.separator)\r\n        class_n += styles.entry_separator + \" \"\r\n    else\r\n        class_n += styles.entry_button + \" \"\r\n\r\n    if(props.separator)\r\n        return <div className={class_n}/>\r\n    else\r\n        return <div className={class_n}> \r\n                    <button onClick={() => props.remove()}>X</button>\r\n                </div>\r\n\r\n}\r\n\r\n\r\nexport default DataAux;","import React from 'react';\r\nimport DataValue from './DataValue';\r\nimport DataAux from './DataAux';\r\n\r\nimport styles from './DataGrid.module.css'\r\n\r\nclass DataEntry extends React.Component{\r\n\r\n    constructor(props){\r\n        super(props)\r\n        this.key = 0;\r\n    }\r\n\r\n    setValue(data,index,val){\r\n        data[index] = val\r\n    }\r\n\r\n    render(){\r\n\r\n        let data = this.props.data;\r\n        let entry = [];\r\n        let label_in_key = 0;\r\n        let label_out_key = 0;\r\n        let entry_value = 0;\r\n        if(this.props.label){\r\n            entry.push(<DataAux key={\"data_aux_separator\" + this.key++} separator={true}/>)\r\n            for(let value = 0; value < this.props.input_labels.length; value++){\r\n                entry.push(<DataValue value={this.props.input_labels[value]} remove={this.props.remove.in.bind(this,value)} \r\n                        callback={this.props.callback.in.bind(this,value)} label={this.props.label}\r\n                        key={\"label_in_value\" + label_in_key++}\r\n                        />)\r\n            }\r\n            entry.push(<DataAux key={\"data_aux_separator\" + this.key++} separator={true} label={true}/>)\r\n            for(let value = 0; value < this.props.output_labels.length; value++){\r\n                entry.push(<DataValue value={this.props.output_labels[value]} remove={this.props.remove.out.bind(this,value)} \r\n                        callback={this.props.callback.out.bind(this,value)} label={this.props.label}\r\n                        key={\"label_out_value\" + label_out_key++}\r\n                        />)\r\n            }\r\n        }else{\r\n            entry.push(<DataAux remove={this.props.removeEntry} key={\"data_aux_separator\" + this.key++}/>)\r\n            for(let value = 0; value < data.length; value++)\r\n                entry.push(<DataValue value={data[value]}\r\n                    callback={this.props.callback.bind(this,value)} label={this.props.label}\r\n                    key={\"data_value\" + this.props.index + \"->\" + entry_value++}\r\n                    />)\r\n            entry.splice(this.props.in_size+1,0,<DataValue separator={true} key={\"data_aux_separator\" + this.key++}/>)\r\n        }\r\n        let classname = styles.entry;\r\n        if(this.props.active)\r\n            classname += \" \" + styles.active\r\n        return (\r\n                <div className={classname}>\r\n                    {entry}\r\n                </div>\r\n        )\r\n    }\r\n}\r\n\r\nexport default DataEntry;","import React from 'react';\r\nimport DataEntry from './DataEntry';\r\n\r\nimport styles from './DataGrid.module.css'\r\n\r\nclass DataGrid extends React.Component{\r\n\r\n    constructor(props){\r\n        super();\r\n        this.key = 0;\r\n    }\r\n\r\n    render(){\r\n        let grid = [];\r\n\r\n        let changes = this.props.changes;\r\n\r\n\r\n        let lables = <DataEntry /*key={\"grid_labels_\" + this.key++}*/\r\n                    input_labels={this.props.input_labels} \r\n                    output_labels={this.props.output_labels} \r\n                    remove={changes.remove}\r\n                    callback={changes.changeLabels} \r\n                    label={true}\r\n                />\r\n        \r\n        let data = this.props.data\r\n        let in_size = this.props.input_labels.length\r\n        let out_size = this.props.output_labels.length\r\n        for(let entry = 0; entry < data.length; entry++){\r\n            grid.push(<DataEntry key={\"grid_entry_\" + entry}\r\n                        in_size={in_size} out_size={out_size} \r\n                        data={data[entry]}\r\n                        index = {entry}\r\n                        callback={changes.changeData.bind(this,entry)}\r\n                        removeEntry={changes.removeDataEntry.bind(this,entry)}\r\n                        active = {entry === this.props.currentValue}\r\n                        />)\r\n        }\r\n        return (\r\n            <div /*key={\"Grid_\" + this.key++}*/ className={styles.grid_wrapper}>\r\n                <div className={styles.grid_container}>\r\n                    {lables}\r\n                    <div style={{overflowY:'auto',flex:'1 0 auto',overflowX:'hidden'}}>\r\n                        <div style={{minHeight:'min-content',height:'0'}}>\r\n                            {grid} \r\n                        </div>                 \r\n                    </div>\r\n                </div>\r\n                <div className={styles.grid_container_buttons}>\r\n                    <button onClick={changes.addInput.bind(this)}>Add Input</button>\r\n                    <button onClick={changes.addEntry.bind(this)}>Add entry</button>\r\n                    <button onClick={changes.addOutput.bind(this)}>Add Output</button>\r\n                </div>\r\n            </div>\r\n            \r\n        )\r\n    }\r\n}\r\n\r\nexport default DataGrid;","import React, { useState } from 'react';\r\n\r\nimport styles from './RangeBar.module.css'\r\n\r\nfunction RangeBar(props){\r\n    const step = props.step ? props.step : 1;\r\n    let transform = (val) => {\r\n        if(props.type === \"log\"){\r\n            val = Math.exp(val);\r\n        }\r\n        return val;\r\n    }\r\n\r\n    let inverse = (val) => {\r\n        if(props.type === \"log\"){\r\n            val = Math.log(val);\r\n        }\r\n        return val;\r\n    }\r\n\r\n    const [value, setValue] = useState(props.value ? inverse(props.value) : inverse((props.max-props.min)/2));\r\n    const [displayValue , setDisplayValue] = useState(props.value ? props.value : value)\r\n\r\n    let handleChange = (e) =>{\r\n        let val = step === 1 ? parseInt(e.target.value) : parseFloat(e.target.value);\r\n        setValue(val);\r\n        val = transform(val)\r\n        step === 1 ? setDisplayValue(val) : setDisplayValue(val.toFixed(5));\r\n        if(props.callback)\r\n            props.callback(val)\r\n    }\r\n    const elem = (\r\n            <div className={styles.slidecontainer}>\r\n                <input type=\"range\" min={props.min} max={props.max} value={value} step={props.step ? props.step : 1} class=\"slider\" onChange={(e) => handleChange(e)}/>\r\n                <span id=\"rs-bullet\" className={styles.rs_label}>{props.info}:{displayValue}</span>\r\n            </div>\r\n    )\r\n    return(\r\n        elem\r\n    )\r\n\r\n}\r\nexport default RangeBar;","import React from 'react';\r\n\r\nimport NeuralNetwork from '../../NeuralNetwork/NeuralNetwork'\r\nimport samples from '../../NeuralNetwork/samplesNN'\r\nimport VisualNN from '../Visual/VisualNN'\r\n\r\nimport styles from './Layout.module.css'\r\nimport InfoPanel from './InfoPanel'\r\nimport DataGrid from '../DataGrid/DataGrid';\r\nimport Expression from '../Expression/Expression';\r\nimport RangeBar from '../RangeBar/RangeBar';\r\n\r\n\r\nclass Layout extends React.Component{\r\n\r\n    constructor(props){\r\n        super(props);\r\n\r\n        this.nn = new NeuralNetwork(2,2)\r\n        this.setNNFromSample(\"sample1\")\r\n        let temp_inp_labels = [];\r\n        let temp_out_labels = [];\r\n        this.input_key = 0;\r\n        this.output_key = 0;\r\n\r\n        for(let  i = 0; i < this.nn.getInputLayerSize();i++){\r\n            temp_inp_labels.push(\"Input_\"+this.input_key++);\r\n        }\r\n        for(let  i = 0; i < this.nn.getOutputLayerSize();i++){\r\n            temp_out_labels.push(\"Output_\"+this.output_key++);\r\n        }\r\n\r\n        this.state = {\r\n            neuralNetwork : this.nn,\r\n            data : [[0.05,0.1,0.01,0.99]],\r\n            input_labels: temp_inp_labels,\r\n            output_labels: temp_out_labels,\r\n        }\r\n        this.resetDataIndex();\r\n        //console.log(this.nn.export())\r\n    }\r\n    resetDataIndex(){\r\n        this.current_index = -1;\r\n        this.input_index = 0;\r\n    }\r\n\r\n    setNNFromSample(index){\r\n        this.nn.import(samples[index]);\r\n    }\r\n\r\n    generateNN(){\r\n        let input_size = null;\r\n        if(this.state.input_labels.length > 0)\r\n            input_size = this.state.input_labels.length\r\n        let output_size = null;\r\n        if(this.state.output_labels.length > 0)\r\n            output_size = this.state.output_labels.length\r\n        this.nn.createRandomNN(input_size,output_size);\r\n        this.setNN();\r\n    }\r\n\r\n    randomizeNN(){\r\n        this.nn.randomize();\r\n        this.setNN();\r\n    }\r\n    getDataEntry() {\r\n        let input_data = null;\r\n        let output_data = null;\r\n        if(this.state.data.length !== 0){\r\n            input_data = this.state.data[this.input_index].slice(0,this.state.input_labels.length);\r\n            output_data = this.state.data[this.input_index].slice(-this.state.output_labels.length);\r\n        }\r\n        return [input_data, output_data]\r\n    }\r\n    incrementEntryIndex(){\r\n        this.current_index = this.input_index\r\n        if(this.state.data.length > 0)\r\n            this.input_index = (this.input_index+1)%this.state.data.length;\r\n    }\r\n    feedForward(){\r\n        let [input_data, output_data] = this.getDataEntry();\r\n        this.incrementEntryIndex();\r\n        this.nn.feedforward(input_data,output_data);\r\n        this.setNN();\r\n    }\r\n\r\n    feedForwardStepNode(){\r\n        this.current_index = this.input_index\r\n        let [input_data, output_data] = this.getDataEntry();\r\n        let next = this.nn.feedforwardStepNode(input_data,output_data);\r\n        if(next) this.incrementEntryIndex();\r\n        this.setNN();\r\n    }\r\n    feedForwardStepLayer(){\r\n        this.current_index = this.input_index\r\n        let [input_data, output_data] = this.getDataEntry();\r\n        let next = this.nn.feedforwardStepLayer(input_data,output_data);\r\n        if(next) this.incrementEntryIndex();\r\n        this.setNN();\r\n    }\r\n\r\n    train(){\r\n        this.resetDataIndex();\r\n        let input_data = [];\r\n        let output_data = [];\r\n        this.state.data.forEach(d => {\r\n            input_data.push(d.slice(0,this.state.input_labels.length))\r\n            output_data.push(d.slice(-this.state.output_labels.length))\r\n        })\r\n        this.nn.train(input_data,output_data,100);\r\n        this.setNN();\r\n    }\r\n\r\n    backpropagate(){\r\n        this.current_index = this.input_index\r\n        let [input_data, output_data] = this.getDataEntry();\r\n        if(input_data == null && output_data == null) return;\r\n        this.nn.backpropagation(input_data,output_data);\r\n        this.incrementEntryIndex();\r\n        this.setNN();\r\n    }\r\n\r\n    backpropagateLayer(){\r\n        this.current_index = this.input_index\r\n        let [input_data, output_data] = this.getDataEntry();\r\n        if(input_data == null && output_data == null) return;\r\n        let next = this.nn.backpropagationLayer(input_data,output_data);\r\n        if(next) this.incrementEntryIndex();\r\n        this.setNN();\r\n    }\r\n    backpropagateNode(){\r\n        this.current_index = this.input_index\r\n        let [input_data, output_data] = this.getDataEntry();\r\n        if(input_data == null && output_data == null) return;\r\n        let next = this.nn.backpropagationNode(input_data,output_data);\r\n        if(next) this.incrementEntryIndex();\r\n        this.setNN();\r\n    }\r\n\r\n    addNode(layer){\r\n        this.nn.addNode(layer);\r\n        this.setNN();\r\n    }\r\n\r\n    addLayer(layer){\r\n        this.nn.addLayer(layer);\r\n        this.setNN();\r\n    }\r\n\r\n    changeActivationLayer(layer,name){\r\n        this.nn.setLayerActivation(layer,name)\r\n        this.setNN();\r\n    }\r\n\r\n    setNN(){\r\n        this.setState({\r\n            neuralNetwork : this.nn,\r\n        })\r\n    }\r\n\r\n    addEntry(){\r\n        let temp = this.state.data;\r\n        let new_entry = [];\r\n        for(let i = 0; i < this.state.input_labels.length + this.state.output_labels.length;i++)\r\n            new_entry.push(0);\r\n        temp.push(new_entry)\r\n        this.setState({data : temp})\r\n    }\r\n\r\n    addInput(){\r\n        let temp = this.state.data;\r\n        temp.forEach(t => t.splice(this.state.input_labels.length,0,0))\r\n        let labels_t = this.state.input_labels\r\n        labels_t.push(\"Input_\"+this.input_key++);\r\n        this.nn.addInputNode();\r\n        this.setState({\r\n            neuralNetwork : this.nn,\r\n            data : temp,\r\n            input_labels : labels_t\r\n        })\r\n    }\r\n\r\n    addOutput(){\r\n        let temp = this.state.data;\r\n        temp.forEach(t => t.push(0))\r\n        let labels_t = this.state.output_labels\r\n        labels_t.push(\"Output_\"+this.output_key++);\r\n        this.nn.addOutputNode();\r\n        this.setState({\r\n            neuralNetwork : this.nn,\r\n            data : temp,\r\n            output_labels : labels_t\r\n        })\r\n    }\r\n\r\n    removeDataEntry(index){\r\n        let temp = this.state.data;\r\n        temp.splice(index,1);\r\n        this.input_index = (this.input_index+this.state.data.length)%+this.state.data.length;\r\n        if(index === this.current_index)\r\n            this.current_index = -1;\r\n        this.setState({\r\n            data : temp,\r\n        })\r\n    }\r\n\r\n    removeInput(index){\r\n        let temp = this.state.data;\r\n        temp.forEach(t => t.splice(index,1))\r\n        let labels_t = this.state.input_labels\r\n        labels_t.splice(index,1)\r\n        this.nn.deleteInputNode(index);\r\n        this.setState({\r\n            neuralNetwork : this.nn,\r\n            data : temp,\r\n            input_labels : labels_t\r\n        })\r\n    }\r\n    removeOutput(index){\r\n        let temp = this.state.data;\r\n        temp.forEach(t => t.splice(index,1))\r\n        let labels_t = this.state.output_labels\r\n        labels_t.splice(index,1)\r\n        this.nn.deleteOutputNode(index);\r\n        this.setState({\r\n            neuralNetwork : this.nn,\r\n            data : temp,\r\n            output_labels : labels_t\r\n        })\r\n    }\r\n    changeInputLabels(value,new_value){\r\n        let temp = this.state.input_labels;\r\n        temp[value] = new_value;\r\n        this.setState({\r\n            input_labels : temp\r\n        })\r\n    }\r\n    changeOutputLabels(value,new_value){\r\n        let temp = this.state.output_labels;\r\n        temp[value] = new_value;\r\n        this.setState({\r\n            output_labels : temp\r\n        })\r\n    }\r\n    changeData(entry,value,new_value){\r\n        let temp = this.state.data;\r\n        temp[entry][value] = new_value;\r\n        this.setState({\r\n            data : temp\r\n        })\r\n    }\r\n\r\n    \r\n\r\n    render(){\r\n        //console.log(\"a\");\r\n        //let input_size = this.state.neuralNetwork.getInputLayerSize();\r\n        let changes = {\r\n            addEntry : this.addEntry.bind(this),\r\n            addInput : this.addInput.bind(this),\r\n            addOutput : this.addOutput.bind(this),\r\n            remove : { \r\n                in : this.removeInput.bind(this),\r\n                out : this.removeOutput.bind(this),\r\n                },\r\n            changeLabels : { \r\n                in : this.changeInputLabels.bind(this),\r\n                out : this.changeOutputLabels.bind(this),\r\n                },\r\n            removeDataEntry : this.removeDataEntry.bind(this),\r\n            changeData : this.changeData.bind(this),\r\n        }\r\n        let NNfunc = {\r\n            addNode : this.addNode.bind(this),\r\n            addLayer : this.addLayer.bind(this),\r\n            changeActivation : this.changeActivationLayer.bind(this)\r\n        }\r\n        return (\r\n            <div className={styles.splitScreen}>\r\n                <div className={styles.leftPane}>\r\n                    <InfoPanel/>\r\n                </div>\r\n                <div className={styles.rightPane}>\r\n                    <div style={{display:'flex',flexDirection:'column',flex:'1 0 auto'}}>\r\n                        <div style={{height:'40%',display:'flex',flexDirection:'column'}}>\r\n                            <DataGrid data={this.state.data} \r\n                                        input_labels={this.state.input_labels} \r\n                                        output_labels={this.state.output_labels} \r\n                                        changes={changes}\r\n                                        currentValue={this.current_index}\r\n                            />\r\n                        </div>\r\n                        <div style={{height:'60%',display:'flex',flexDirection:'column'}}>\r\n                            <VisualNN neuralNetwork={this.state.neuralNetwork} num={this.state.num} func={NNfunc}/>\r\n                            <div className={styles.buttons_container} style={{flex:'0 0 auto'}}>\r\n                                <div className={styles.div_buttons_container}>\r\n                                    <button onClick={this.feedForward.bind(this)}>FeedForward</button>\r\n                                    <button onClick={this.feedForwardStepLayer.bind(this)}>FeedForward Step Layer</button>\r\n                                    <button onClick={this.feedForwardStepNode.bind(this)}>FeedForward Step Node</button>\r\n                                </div> \r\n                                <div className={styles.div_buttons_container}>\r\n                                    <button onClick={this.backpropagate.bind(this)}>Backpropagate</button>\r\n                                    <button onClick={this.backpropagateLayer.bind(this)}>Backpropagate Step Layer</button>\r\n                                    <button onClick={this.backpropagateNode.bind(this)}>Backpropagate Step Node</button>\r\n                                </div>\r\n                                <div className={styles.div_buttons_container}>\r\n                                    <button onClick={this.randomizeNN.bind(this)}>Randomize</button>\r\n                                    <button onClick={this.generateNN.bind(this)}>Generate</button>\r\n                                    <button onClick={this.train.bind(this)}>Train</button>\r\n                                    <RangeBar \r\n                                        min={1}\r\n                                        max={5000}\r\n                                        type=\"linear\"\r\n                                        value={this.state.neuralNetwork.getTrainingTimes()} \r\n                                        callback={(e) => this.state.neuralNetwork.setTrainingTimes(e)}\r\n                                        info=\"Train iterations\"/>\r\n                                    <RangeBar min={-10}\r\n                                        max={0}\r\n                                        step={0.01}\r\n                                        type=\"log\" \r\n                                        value={this.state.neuralNetwork.getLearningRate()} \r\n                                        callback={(e) => this.state.neuralNetwork.setLearningRate(e)}\r\n                                        info=\"Learning rate\"/>\r\n                                </div>\r\n                                \r\n                            </div>\r\n                            <div style={{flex:'3 0 auto', overflowY:'auto'}}>\r\n                                <Expression expressions={this.state.neuralNetwork.expression}/>\r\n                            </div>\r\n                        </div>\r\n                    </div>\r\n                    \r\n                </div>\r\n            </div>\r\n        )\r\n    }\r\n\r\n}\r\n\r\nexport default Layout;\r\n\r\n\r\n/*\r\n\r\n<div className={styles.splitScreen}>\r\n                <div className={styles.leftPane}>\r\n                    <InfoPanel/>\r\n                </div>\r\n                <div className={styles.rightPane}>\r\n                    <div className={styles.rightPane_section}>\r\n                        <DataGrid data={this.state.data} \r\n                                    input_labels={this.state.input_labels} \r\n                                    output_labels={this.state.output_labels} \r\n                                    changes={changes}\r\n                        />\r\n                        <VisualNN neuralNetwork={this.state.neuralNetwork} num={this.state.num}/>\r\n                        <div>\r\n                            <button onClick={this.feedForward.bind(this)}>FeedForward</button>\r\n                            <button onClick={this.feedForwardStepNode.bind(this)}>FeedForward Step Node</button>\r\n                            <button onClick={this.feedForwardStepLayer.bind(this)}>FeedForward Step Layer</button>\r\n                            <button onClick={this.randomizeNN.bind(this)}>Randomize</button>\r\n                            <button onClick={this.generateNN.bind(this)}>Generate</button>\r\n                            <button onClick={this.train.bind(this)}>Train</button>\r\n                        </div>\r\n                    </div>\r\n                </div>\r\n            </div>\r\n\r\n*/","import './App.css';\nimport Navbar from './components/Navbar/Navbar';\nimport Layout from './components/Layout/Layout';\n\nfunction App() {\n  return (\n    <div className=\"App\" style={{height:'100vh', display:'flex' , 'flexDirection':'column' }}>\n      <Navbar></Navbar> \n      <Layout/>\n    </div>\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n","// extracted by mini-css-extract-plugin\nmodule.exports = {\"Topbar\":\"Topbar_Topbar__XaKPb\",\"TopbarItem\":\"Topbar_TopbarItem__yNKj6\",\"isNotActive\":\"Topbar_isNotActive__2rJES\",\"isActive\":\"Topbar_isActive__i1OG7\"};","// extracted by mini-css-extract-plugin\nmodule.exports = {\"node_data\":\"Node_node_data__2MR_S\",\"node\":\"Node_node__Z0DSe\",\"circle\":\"Node_circle__10tnP\",\"isActive\":\"Node_isActive__3eh_8\"};","// extracted by mini-css-extract-plugin\nmodule.exports = {\"_navbar\":\"Navbar__navbar__7sUy8\",\"_navbar-logo\":\"Navbar__navbar-logo__1dElB\",\"_navbar_left\":\"Navbar__navbar_left__1bpMt\",\"_navbar-right\":\"Navbar__navbar-right__2CCJT\"};","// extracted by mini-css-extract-plugin\nmodule.exports = {\"rs_label\":\"RangeBar_rs_label__2Uggo\",\"slidecontainer\":\"RangeBar_slidecontainer__2OgoG\"};"],"sourceRoot":""}